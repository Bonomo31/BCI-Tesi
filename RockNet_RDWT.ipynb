{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI Giuseppe Bonomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kExkM1UKKKJ-",
    "outputId": "360334b4-6e59-4d0e-b46a-cb0ba6750b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: decorator in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (3.1.5)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (3.10.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (24.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (1.15.1)\n",
      "Requirement already satisfied: tqdm in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (4.55.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.12.14)\n",
      "Requirement already satisfied: PyWavelets in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from PyWavelets) (1.26.4)\n",
      "Requirement already satisfied: braindecode==0.3 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: mne in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (1.9.0)\n",
      "Requirement already satisfied: numpy in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (2.2.3)\n",
      "Requirement already satisfied: scipy in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (1.15.1)\n",
      "Requirement already satisfied: resampy in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (0.4.3)\n",
      "Requirement already satisfied: matplotlib in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (3.10.0)\n",
      "Requirement already satisfied: h5py in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from braindecode==0.3) (3.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (4.55.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from matplotlib->braindecode==0.3) (2.9.0.post0)\n",
      "Requirement already satisfied: decorator in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne->braindecode==0.3) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne->braindecode==0.3) (3.1.5)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne->braindecode==0.3) (0.4)\n",
      "Requirement already satisfied: pooch>=1.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne->braindecode==0.3) (1.8.2)\n",
      "Requirement already satisfied: tqdm in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from mne->braindecode==0.3) (4.66.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pandas->braindecode==0.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pandas->braindecode==0.3) (2025.1)\n",
      "Requirement already satisfied: numba>=0.53 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from resampy->braindecode==0.3) (0.61.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from numba>=0.53->resampy->braindecode==0.3) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne->braindecode==0.3) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne->braindecode==0.3) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->braindecode==0.3) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from jinja2->mne->braindecode==0.3) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.3) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giuseppebonomo/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.3) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#!git clone https://github.com/marco-siino/EEG-ATCNet.git\n",
    "!pip install mne\n",
    "!pip install PyWavelets\n",
    "#Le ulitme versioni non sono compatibili con le librerie usate\n",
    "#in preprocess_HGD.py, quindi si è optato a utilizzare una versione meno recente\n",
    "!pip install braindecode==0.3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"/Users/giuseppebonomo/Desktop/UNIPA CdLM Ing_Informatica/Tesi/CodiceBCI/EEG-ATCNet\")\n",
    "\n",
    "import models\n",
    "\n",
    "#from preprocess import get_data\n",
    "# from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anMFWoueUv95"
   },
   "source": [
    "# Organize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PM6WBGY4fBe9"
   },
   "outputs": [],
   "source": [
    "# Creare la cartella \"dataset\" e \"results\" se non esistono già\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "\n",
    "#Crea la sotto-cartella train e test\n",
    "os.makedirs(\"dataset/train\", exist_ok=True)\n",
    "os.makedirs(\"dataset/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport requests\\nfrom pathlib import Path\\nfrom tqdm import tqdm\\n\\n# Definizione URL base\\ntrain_url = \"https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/train\"\\ntest_url = \"https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/test\"\\n\\n# Creazione cartelle se non esistono\\ntrain_dir = Path(\"dataset/train\")\\ntest_dir = Path(\"dataset/test\")\\ntrain_dir.mkdir(parents=True, exist_ok=True)\\ntest_dir.mkdir(parents=True, exist_ok=True)\\n\\ndef download_file(url, filepath):\\n    #Scarica un file con una barra di avanzamento\\n    response = requests.get(url, stream=True)\\n    if response.status_code == 200:\\n        total_size = int(response.headers.get(\"content-length\", 0))\\n        with open(filepath, \"wb\") as f, tqdm(\\n            desc=filepath.name, total=total_size, unit=\"B\", unit_scale=True\\n        ) as bar:\\n            for chunk in response.iter_content(chunk_size=1024):\\n                f.write(chunk)\\n                bar.update(len(chunk))\\n    else:\\n        print(f\"Errore nel download di {url}: {response.status_code}\")\\n\\n# Scarico i file di train e test\\nfor i in range(1, 15):\\n    train_file = train_dir / f\"{i}.mat\"\\n    test_file = test_dir / f\"{i}.mat\"\\n\\n    download_file(f\"{train_url}/{i}.mat\", train_file)\\n    download_file(f\"{test_url}/{i}.mat\", test_file)\\n\\nprint(\"Download completato!\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Definizione URL base\n",
    "train_url = \"https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/train\"\n",
    "test_url = \"https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/test\"\n",
    "\n",
    "# Creazione cartelle se non esistono\n",
    "train_dir = Path(\"dataset/train\")\n",
    "test_dir = Path(\"dataset/test\")\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_file(url, filepath):\n",
    "    #Scarica un file con una barra di avanzamento\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        with open(filepath, \"wb\") as f, tqdm(\n",
    "            desc=filepath.name, total=total_size, unit=\"B\", unit_scale=True\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "    else:\n",
    "        print(f\"Errore nel download di {url}: {response.status_code}\")\n",
    "\n",
    "# Scarico i file di train e test\n",
    "for i in range(1, 15):\n",
    "    train_file = train_dir / f\"{i}.mat\"\n",
    "    test_file = test_dir / f\"{i}.mat\"\n",
    "\n",
    "    download_file(f\"{train_url}/{i}.mat\", train_file)\n",
    "    download_file(f\"{test_url}/{i}.mat\", test_file)\n",
    "\n",
    "print(\"Download completato!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XKTWW88RTAU5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Scarico i dati di train e test per High Gamma Dataset\\ntrain = \"https://gin.g-node.org/robintibor/high-gamma-dataset/src/master/data/train\"\\ntest = \"https://gin.g-node.org/robintibor/high-gamma-dataset/src/master/data/test\"\\n\\n#Assegno ad ogni dato un id T per train e E per evaluation, aggiungendoli alla cartella s{i}\\nfor i in range(1, 15):\\n    os.system(f\"wget -O dataset/train/{i}.mat {train}/{i}.mat\")\\n    os.system(f\"wget -O dataset/test/{i}.mat {test}/{i}.mat\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Scarico i dati di train e test per High Gamma Dataset\n",
    "train = \"https://gin.g-node.org/robintibor/high-gamma-dataset/src/master/data/train\"\n",
    "test = \"https://gin.g-node.org/robintibor/high-gamma-dataset/src/master/data/test\"\n",
    "\n",
    "#Assegno ad ogni dato un id T per train e E per evaluation, aggiungendoli alla cartella s{i}\n",
    "for i in range(1, 15):\n",
    "    os.system(f\"wget -O dataset/train/{i}.mat {train}/{i}.mat\")\n",
    "    os.system(f\"wget -O dataset/test/{i}.mat {test}/{i}.mat\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "KrRurPbzKuRH",
    "outputId": "29e5ae86-abd1-45b5-c7a2-ab508986e733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Download the dataset.\\nbase_url = \"https://bnci-horizon-2020.eu/database/data-sets/001-2014/\"\\nsave_path = \"dataset/\"\\n\\nfor i in range(1, 10):  # Da A01 a A09\\n    for suffix in [\"T\", \"E\"]:  # T per training, E per evaluation\\n        filename = f\"A{i:02d}{suffix}.mat\"\\n        url = base_url + filename\\n        os.system(f\"wget -O {save_path}s{i}/{filename} {url}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Download the dataset.\n",
    "base_url = \"https://bnci-horizon-2020.eu/database/data-sets/001-2014/\"\n",
    "save_path = \"dataset/\"\n",
    "\n",
    "for i in range(1, 10):  # Da A01 a A09\n",
    "    for suffix in [\"T\", \"E\"]:  # T per training, E per evaluation\n",
    "        filename = f\"A{i:02d}{suffix}.mat\"\n",
    "        url = base_url + filename\n",
    "        os.system(f\"wget -O {save_path}s{i}/{filename} {url}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKIHsRuSU-zn"
   },
   "source": [
    "# Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n6r2i2nHVDHa"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "def draw_learning_curves(history, sub):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy - subject: ' + str(sub))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss - subject: ' + str(sub))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def draw_confusion_matrix(cf_matrix, sub, results_path, classes_labels):\n",
    "    # Generate confusion matrix plot\n",
    "    display_labels = classes_labels\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,\n",
    "                                display_labels=display_labels)\n",
    "    disp.plot()\n",
    "    disp.ax_.set_xticklabels(display_labels, rotation=12)\n",
    "    plt.title('Confusion Matrix of Subject: ' + sub )\n",
    "    plt.savefig(results_path + '/subject_' + sub + '.png')\n",
    "    plt.show()\n",
    "\n",
    "def draw_performance_barChart(num_sub, metric, label):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = list(range(1, num_sub+1))\n",
    "    ax.bar(x, metric, 0.5, label=label)\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_xlabel(\"Subject\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_title('Model '+ label + ' per subject')\n",
    "    ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byiRKS6cVQpE"
   },
   "source": [
    "# Preprocessing functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBbRpj7xW3P4"
   },
   "source": [
    "## DB4 (Soft -> Threshold 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lUw3WgVjXEb6"
   },
   "outputs": [],
   "source": [
    "def db4_soft(signal, wavelet='db4', level=4, threshold=5.5):\n",
    "    \"\"\"\n",
    "    Applica la RDWT (Discrete Wavelet Transform) al segnale e lo ricostruisce,\n",
    "    rimuovendo i coefficienti di dettaglio sotto una certa soglia per enfatizzare\n",
    "    le caratteristiche principali del segnale.\n",
    "\n",
    "    Args:\n",
    "    - signal: il segnale da elaborare\n",
    "    - wavelet: tipo di wavelet da utilizzare (default 'db4')\n",
    "    - level: livello della decomposizione (default 4)\n",
    "    - threshold: soglia per i coefficienti di dettaglio (default 0.5)\n",
    "\n",
    "    Returns:\n",
    "    - Il segnale ricostruito dopo la manipolazione della RDWT\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(\"Lunghezza originale:\", signal.shape[-1])  # Dovrebbe essere 1125\n",
    "    coeffs = pywt.wavedec(signal, wavelet, mode='per', level=level)\n",
    "    print(\"Lunghezza coefficiente di approssimazione:\", len(coeffs[0]))\n",
    "\n",
    "    reconstructed_signal = pywt.waverec(coeffs, wavelet, mode='per')\n",
    "    print(\"Lunghezza ricostruita:\", len(reconstructed_signal))\n",
    "\n",
    "    # Decomposizione del segnale in coefficienti\n",
    "    coeffs = pywt.wavedec(signal, wavelet, mode='per', level=level)\n",
    "\n",
    "    # Modifica i coefficienti di dettaglio\n",
    "    # Si applica un threshold sui coefficienti di dettaglio per \"ridurre\" la componente di alta frequenza\n",
    "    coeffs_thresholded = [coeffs[0]]  # Mantieni il coefficiente di approssimazione\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs_thresholded.append(np.where(np.abs(coeffs[i]) < threshold, 0, coeffs[i]))\n",
    "\n",
    "    # Ricostruzione del segnale dai coefficienti modificati\n",
    "    reconstructed_signal = pywt.waverec(coeffs_thresholded, wavelet, mode='per')\n",
    "\n",
    "    # Taglia il segnale ricostruito per mantenerne la stessa lunghezza dell'input\n",
    "    return reconstructed_signal[:len(signal)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_7jS5mAW7X8"
   },
   "source": [
    "## DB4 (Hard -> Threshold 10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lQDSj1UhXQbo"
   },
   "outputs": [],
   "source": [
    "def db4_hard(signal, wavelet='db4', level=4, threshold=10.5):\n",
    "    \"\"\"\n",
    "    Applica la RDWT (Discrete Wavelet Transform) al segnale e lo ricostruisce,\n",
    "    rimuovendo i coefficienti di dettaglio sotto una certa soglia per enfatizzare\n",
    "    le caratteristiche principali del segnale.\n",
    "\n",
    "    Args:\n",
    "    - signal: il segnale da elaborare\n",
    "    - wavelet: tipo di wavelet da utilizzare (default 'db4')\n",
    "    - level: livello della decomposizione (default 4)\n",
    "    - threshold: soglia per i coefficienti di dettaglio (default 0.5)\n",
    "\n",
    "    Returns:\n",
    "    - Il segnale ricostruito dopo la manipolazione della RDWT\n",
    "    \"\"\"\n",
    "\n",
    "    # Decomposizione del segnale in coefficienti\n",
    "    coeffs = pywt.wavedec(signal, wavelet, mode='per', level=level)\n",
    "\n",
    "    # Modifica i coefficienti di dettaglio\n",
    "    # Si applica un threshold sui coefficienti di dettaglio per \"ridurre\" la componente di alta frequenza\n",
    "    coeffs_thresholded = [coeffs[0]]  # Mantieni il coefficiente di approssimazione\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs_thresholded.append(np.where(np.abs(coeffs[i]) < threshold, 0, coeffs[i]))\n",
    "\n",
    "    # Ricostruzione del segnale dai coefficienti modificati\n",
    "    reconstructed_signal = pywt.waverec(coeffs_thresholded, wavelet, mode='per')\n",
    "\n",
    "    # Taglia il segnale ricostruito per mantenerne la stessa lunghezza dell'input\n",
    "    return reconstructed_signal[:len(signal)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NG7RQTKWZjc"
   },
   "source": [
    "## RDWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1l6F2E0iVovM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import pywt\n",
    "\n",
    "def rational_dilated_wavelet_transform(sig, wavelet='db4', levels=4, dilation_factors=None, threshold=5.5):\n",
    "    \"\"\"\n",
    "    Applica la Rational Dilated Wavelet Transform (RDWT) a un segnale EEG multidimensionale.\n",
    "\n",
    "    Args:\n",
    "    - sig: array numpy di forma (eventi, 1, canali, campioni)\n",
    "    - wavelet: tipo di wavelet da utilizzare (default 'db4')\n",
    "    - levels: numero di livelli di decomposizione (default 4)\n",
    "    - dilation_factors: lista di fattori di dilatazione razionale (default: [3/2, 5/3, 7/4, ...])\n",
    "    - threshold: soglia per i coefficienti di dettaglio (default 5.5)\n",
    "\n",
    "    Returns:\n",
    "    - Segnale ricostruito con la RDWT (stessa dimensione dell'input)\n",
    "    \"\"\"\n",
    "    eventi, _, canali, campioni = sig.shape\n",
    "    print(\"Lunghezza originale del segnale:\", sig.shape)\n",
    "\n",
    "    if dilation_factors is None:\n",
    "        dilation_factors = [3/2, 5/3, 7/4, 9/5]\n",
    "\n",
    "    coeffs_approx = sig.copy()  # Inizializza con il segnale originale\n",
    "    detail_coeffs = []\n",
    "\n",
    "    for i in range(levels):\n",
    "        factor = dilation_factors[i]\n",
    "        wavelet_filter = pywt.Wavelet(wavelet)\n",
    "        lo_d, hi_d = wavelet_filter.dec_lo, wavelet_filter.dec_hi\n",
    "\n",
    "        # Ridimensionamento dei filtri\n",
    "        lo_d = signal.resample(lo_d, int(len(lo_d) * factor))\n",
    "        hi_d = signal.resample(hi_d, int(len(hi_d) * factor))\n",
    "\n",
    "        print(f\"Livello {i+1}: coeffs_approx shape {coeffs_approx.shape}, lo_d shape {lo_d.shape}, hi_d shape {hi_d.shape}\")\n",
    "\n",
    "        approx = np.zeros_like(coeffs_approx)\n",
    "        detail = np.zeros_like(coeffs_approx)\n",
    "\n",
    "        # Applica la convoluzione per ogni canale EEG\n",
    "        for e in range(eventi):\n",
    "            for c in range(canali):\n",
    "                approx[e, 0, c, :] = np.convolve(coeffs_approx[e, 0, c, :], lo_d, mode='same')\n",
    "                detail[e, 0, c, :] = np.convolve(coeffs_approx[e, 0, c, :], hi_d, mode='same')\n",
    "\n",
    "                # Soglia sui coefficienti di dettaglio\n",
    "                detail[e, 0, c, np.abs(detail[e, 0, c, :]) < threshold] = 0\n",
    "\n",
    "        detail_coeffs.append(detail)\n",
    "        coeffs_approx = approx  # Passa l'approssimazione al livello successivo\n",
    "\n",
    "    # Ricostruzione del segnale\n",
    "    reconstructed = coeffs_approx.copy()\n",
    "    for i in range(levels-1, -1, -1):\n",
    "        reconstructed += detail_coeffs[i]\n",
    "\n",
    "    print(\"Lunghezza del segnale ricostruito:\", reconstructed.shape)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8AAXepUzYZOv"
   },
   "outputs": [],
   "source": [
    "def apply_preprocessing (signals_data, preprocessing):\n",
    "  if preprocessing==\"none\":\n",
    "    return signals_data\n",
    "  elif preprocessing==\"db4_soft\":\n",
    "    return db4_soft(signals_data)\n",
    "  elif preprocessing==\"db4_hard\":\n",
    "    return db4_hard(signals_data)\n",
    "  elif preprocessing==\"rdwt\":\n",
    "    return rational_dilated_wavelet_transform(signals_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcIk3eTxUeqE"
   },
   "source": [
    "# Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiavi principali del file .mat: ['ch1', 'ch10', 'ch100', 'ch101', 'ch102', 'ch103', 'ch104', 'ch105', 'ch106', 'ch107', 'ch108', 'ch109', 'ch11', 'ch110', 'ch111', 'ch112', 'ch113', 'ch114', 'ch115', 'ch116', 'ch117', 'ch118', 'ch119', 'ch12', 'ch120', 'ch121', 'ch122', 'ch123', 'ch124', 'ch125', 'ch126', 'ch127', 'ch128', 'ch129', 'ch13', 'ch130', 'ch131', 'ch132', 'ch133', 'ch14', 'ch15', 'ch16', 'ch17', 'ch18', 'ch19', 'ch2', 'ch20', 'ch21', 'ch22', 'ch23', 'ch24', 'ch25', 'ch26', 'ch27', 'ch28', 'ch29', 'ch3', 'ch30', 'ch31', 'ch32', 'ch33', 'ch34', 'ch35', 'ch36', 'ch37', 'ch38', 'ch39', 'ch4', 'ch40', 'ch41', 'ch42', 'ch43', 'ch44', 'ch45', 'ch46', 'ch47', 'ch48', 'ch49', 'ch5', 'ch50', 'ch51', 'ch52', 'ch53', 'ch54', 'ch55', 'ch56', 'ch57', 'ch58', 'ch59', 'ch6', 'ch60', 'ch61', 'ch62', 'ch63', 'ch64', 'ch65', 'ch66', 'ch67', 'ch68', 'ch69', 'ch7', 'ch70', 'ch71', 'ch72', 'ch73', 'ch74', 'ch75', 'ch76', 'ch77', 'ch78', 'ch79', 'ch8', 'ch80', 'ch81', 'ch82', 'ch83', 'ch84', 'ch85', 'ch86', 'ch87', 'ch88', 'ch89', 'ch9', 'ch90', 'ch91', 'ch92', 'ch93', 'ch94', 'ch95', 'ch96', 'ch97', 'ch98', 'ch99', 'dat', 'mnt', 'mrk', 'nfo', '~obj_pointed_by_100280', '~obj_pointed_by_100592', '~obj_pointed_by_100904', '~obj_pointed_by_101216', '~obj_pointed_by_101856', '~obj_pointed_by_102168', '~obj_pointed_by_102480', '~obj_pointed_by_102792', '~obj_pointed_by_10296', '~obj_pointed_by_103432', '~obj_pointed_by_103736', '~obj_pointed_by_104040', '~obj_pointed_by_104344', '~obj_pointed_by_104976', '~obj_pointed_by_105288', '~obj_pointed_by_105600', '~obj_pointed_by_105912', '~obj_pointed_by_10600', '~obj_pointed_by_106544', '~obj_pointed_by_106848', '~obj_pointed_by_107152', '~obj_pointed_by_107456', '~obj_pointed_by_107768', '~obj_pointed_by_108952', '~obj_pointed_by_10904', '~obj_pointed_by_109264', '~obj_pointed_by_109568', '~obj_pointed_by_109872', '~obj_pointed_by_110176', '~obj_pointed_by_110808', '~obj_pointed_by_111120', '~obj_pointed_by_111432', '~obj_pointed_by_111744', '~obj_pointed_by_11216', '~obj_pointed_by_112384', '~obj_pointed_by_112696', '~obj_pointed_by_113008', '~obj_pointed_by_113320', '~obj_pointed_by_114504', '~obj_pointed_by_114816', '~obj_pointed_by_115128', '~obj_pointed_by_11528', '~obj_pointed_by_115440', '~obj_pointed_by_116080', '~obj_pointed_by_116392', '~obj_pointed_by_116704', '~obj_pointed_by_117016', '~obj_pointed_by_117656', '~obj_pointed_by_117960', '~obj_pointed_by_118272', '~obj_pointed_by_118584', '~obj_pointed_by_119224', '~obj_pointed_by_119536', '~obj_pointed_by_119848', '~obj_pointed_by_120160', '~obj_pointed_by_120800', '~obj_pointed_by_121112', '~obj_pointed_by_121424', '~obj_pointed_by_12168', '~obj_pointed_by_121736', '~obj_pointed_by_122048', '~obj_pointed_by_122360', '~obj_pointed_by_122672', '~obj_pointed_by_122984', '~obj_pointed_by_123624', '~obj_pointed_by_12480', '~obj_pointed_by_12784', '~obj_pointed_by_13088', '~obj_pointed_by_135528', '~obj_pointed_by_135840', '~obj_pointed_by_136152', '~obj_pointed_by_136464', '~obj_pointed_by_137104', '~obj_pointed_by_13720', '~obj_pointed_by_137416', '~obj_pointed_by_138056', '~obj_pointed_by_138368', '~obj_pointed_by_138680', '~obj_pointed_by_138992', '~obj_pointed_by_139632', '~obj_pointed_by_139944', '~obj_pointed_by_14024', '~obj_pointed_by_140256', '~obj_pointed_by_140568', '~obj_pointed_by_140880', '~obj_pointed_by_141520', '~obj_pointed_by_141832', '~obj_pointed_by_142144', '~obj_pointed_by_142456', '~obj_pointed_by_143096', '~obj_pointed_by_14328', '~obj_pointed_by_143408', '~obj_pointed_by_143720', '~obj_pointed_by_144032', '~obj_pointed_by_144672', '~obj_pointed_by_144984', '~obj_pointed_by_14632', '~obj_pointed_by_14944', '~obj_pointed_by_15256', '~obj_pointed_by_15736', '~obj_pointed_by_16040', '~obj_pointed_by_16672', '~obj_pointed_by_16984', '~obj_pointed_by_17296', '~obj_pointed_by_17608', '~obj_pointed_by_18248', '~obj_pointed_by_18560', '~obj_pointed_by_18872', '~obj_pointed_by_19184', '~obj_pointed_by_19824', '~obj_pointed_by_20136', '~obj_pointed_by_20440', '~obj_pointed_by_20744', '~obj_pointed_by_21376', '~obj_pointed_by_21680', '~obj_pointed_by_21992', '~obj_pointed_by_22304', '~obj_pointed_by_22944', '~obj_pointed_by_23248', '~obj_pointed_by_23552', '~obj_pointed_by_23856', '~obj_pointed_by_24488', '~obj_pointed_by_24800', '~obj_pointed_by_25112', '~obj_pointed_by_25424', '~obj_pointed_by_26056', '~obj_pointed_by_26360', '~obj_pointed_by_26992', '~obj_pointed_by_27304', '~obj_pointed_by_27616', '~obj_pointed_by_27928', '~obj_pointed_by_28240', '~obj_pointed_by_28880', '~obj_pointed_by_29480', '~obj_pointed_by_29792', '~obj_pointed_by_30432', '~obj_pointed_by_30744', '~obj_pointed_by_31056', '~obj_pointed_by_31368', '~obj_pointed_by_3160', '~obj_pointed_by_32008', '~obj_pointed_by_32320', '~obj_pointed_by_32632', '~obj_pointed_by_32944', '~obj_pointed_by_33584', '~obj_pointed_by_33896', '~obj_pointed_by_34208', '~obj_pointed_by_34520', '~obj_pointed_by_3472', '~obj_pointed_by_35152', '~obj_pointed_by_35464', '~obj_pointed_by_35776', '~obj_pointed_by_36088', '~obj_pointed_by_36400', '~obj_pointed_by_37040', '~obj_pointed_by_37352', '~obj_pointed_by_37664', '~obj_pointed_by_3784', '~obj_pointed_by_37976', '~obj_pointed_by_38288', '~obj_pointed_by_38928', '~obj_pointed_by_39240', '~obj_pointed_by_39552', '~obj_pointed_by_39864', '~obj_pointed_by_40504', '~obj_pointed_by_40816', '~obj_pointed_by_41128', '~obj_pointed_by_41440', '~obj_pointed_by_42080', '~obj_pointed_by_42392', '~obj_pointed_by_42704', '~obj_pointed_by_4272', '~obj_pointed_by_43016', '~obj_pointed_by_43656', '~obj_pointed_by_43960', '~obj_pointed_by_44264', '~obj_pointed_by_44568', '~obj_pointed_by_45208', '~obj_pointed_by_45520', '~obj_pointed_by_4576', '~obj_pointed_by_45832', '~obj_pointed_by_46144', '~obj_pointed_by_46784', '~obj_pointed_by_47096', '~obj_pointed_by_47408', '~obj_pointed_by_47720', '~obj_pointed_by_48360', '~obj_pointed_by_48672', '~obj_pointed_by_4880', '~obj_pointed_by_48984', '~obj_pointed_by_49296', '~obj_pointed_by_49608', '~obj_pointed_by_49920', '~obj_pointed_by_50232', '~obj_pointed_by_50544', '~obj_pointed_by_50856', '~obj_pointed_by_51168', '~obj_pointed_by_51808', '~obj_pointed_by_5184', '~obj_pointed_by_52120', '~obj_pointed_by_52432', '~obj_pointed_by_52736', '~obj_pointed_by_53040', '~obj_pointed_by_53344', '~obj_pointed_by_53984', '~obj_pointed_by_54296', '~obj_pointed_by_54608', '~obj_pointed_by_54920', '~obj_pointed_by_55232', '~obj_pointed_by_5536', '~obj_pointed_by_55544', '~obj_pointed_by_55864', '~obj_pointed_by_56176', '~obj_pointed_by_56488', '~obj_pointed_by_56800', '~obj_pointed_by_57112', '~obj_pointed_by_57752', '~obj_pointed_by_58064', '~obj_pointed_by_58376', '~obj_pointed_by_58688', '~obj_pointed_by_59328', '~obj_pointed_by_59640', '~obj_pointed_by_6168', '~obj_pointed_by_61832', '~obj_pointed_by_62152', '~obj_pointed_by_62800', '~obj_pointed_by_63112', '~obj_pointed_by_6472', '~obj_pointed_by_6784', '~obj_pointed_by_68568', '~obj_pointed_by_69216', '~obj_pointed_by_69536', '~obj_pointed_by_69848', '~obj_pointed_by_7096', '~obj_pointed_by_7736', '~obj_pointed_by_8048', '~obj_pointed_by_8352', '~obj_pointed_by_86432', '~obj_pointed_by_8656', '~obj_pointed_by_86744', '~obj_pointed_by_87056', '~obj_pointed_by_87368', '~obj_pointed_by_87672', '~obj_pointed_by_88304', '~obj_pointed_by_88608', '~obj_pointed_by_88912', '~obj_pointed_by_89216', '~obj_pointed_by_8968', '~obj_pointed_by_90944', '~obj_pointed_by_91256', '~obj_pointed_by_91568', '~obj_pointed_by_91880', '~obj_pointed_by_92512', '~obj_pointed_by_92816', '~obj_pointed_by_93120', '~obj_pointed_by_93424', '~obj_pointed_by_94056', '~obj_pointed_by_94360', '~obj_pointed_by_94664', '~obj_pointed_by_94976', '~obj_pointed_by_95616', '~obj_pointed_by_95928', '~obj_pointed_by_96240', '~obj_pointed_by_96544', '~obj_pointed_by_9688', '~obj_pointed_by_97176', '~obj_pointed_by_97480', '~obj_pointed_by_97784', '~obj_pointed_by_98088', '~obj_pointed_by_98728', '~obj_pointed_by_99032', '~obj_pointed_by_99336', '~obj_pointed_by_99640', '~obj_pointed_by_9992']\n",
      "Shape di ch1: (1, 1225545)\n",
      "Dati di ch1 (primo trial): [-43.988 -43.78  -42.913 ...   1.764   3.395   3.633]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Apre il file .mat in modalità lettura\n",
    "with h5py.File(\"dataset/train/1.mat\", 'r') as f:\n",
    "    # Stampa le chiavi principali nel file .mat\n",
    "    print(\"Chiavi principali del file .mat:\", list(f.keys()))\n",
    "    \n",
    "    # Esamina i dati per una chiave specifica ('ch1')\n",
    "    if 'ch1' in f:\n",
    "        X_data = f['ch1']\n",
    "        print(\"Shape di ch1:\", X_data.shape)\n",
    "        print(\"Dati di ch1 (primo trial):\", X_data[0])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lUYrFX-SUdQP"
   },
   "outputs": [],
   "source": [
    "#%% Training\n",
    "from preprocess import get_data\n",
    "\n",
    "def train(dataset_conf, train_conf, results_path):\n",
    "\n",
    "    # remove the 'result' folder before training\n",
    "    if os.path.exists(results_path):\n",
    "        # Remove the folder and its contents\n",
    "        shutil.rmtree(results_path)\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    # Get the current 'IN' time to calculate the overall training time\n",
    "    in_exp = time.time()\n",
    "    # Create a file to store the path of the best model among several runs\n",
    "    best_models = open(results_path + \"/best models.txt\", \"w\")\n",
    "    # Create a file to store performance during training\n",
    "    log_write = open(results_path + \"/log.txt\", \"w\")\n",
    "\n",
    "    # Get dataset parameters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    print(\"Dataset: \", dataset)\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    print(\"Number of subjects: \", n_sub)\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    print(\"Data path: \", data_path)\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    print(\"Standardization: \", isStandard)\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    print(\"Leave-one-subject-out: \", LOSO)\n",
    "    # Get training hyperparamters\n",
    "    batch_size = train_conf.get('batch_size')\n",
    "    epochs = train_conf.get('epochs')\n",
    "    signal_preprocessing = dataset_conf.get('signal_preprocessing')\n",
    "    patience = train_conf.get('patience')\n",
    "    lr = train_conf.get('lr')\n",
    "    LearnCurves = train_conf.get('LearnCurves') # Plot Learning Curves?\n",
    "    n_train = train_conf.get('n_train')\n",
    "    model_name = train_conf.get('model')\n",
    "    from_logits = train_conf.get('from_logits')\n",
    "\n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, n_train))\n",
    "    kappa = np.zeros((n_sub, n_train))\n",
    "\n",
    "    # Iteration over subjects\n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "\n",
    "        print('\\nTraining on subject ', sub+1)\n",
    "        log_write.write( '\\nTraining on subject '+ str(sub+1) +'\\n')\n",
    "        # Initiating variables to save the best subject accuracy among multiple runs.\n",
    "        BestSubjAcc = 0\n",
    "        bestTrainingHistory = []\n",
    "\n",
    "        # Get training and validation data\n",
    "        print(\"Sto per chiamare get_data\")\n",
    "        X_train, _, y_train_onehot, _, _, _ = get_data(\n",
    "            data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n",
    "\n",
    "        print(\"Dopo get_data\")\n",
    "        print(\"X_train shape is:\"+str(X_train.shape))\n",
    "        # Divide the training data into training and validation\n",
    "        X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "        print(\"\\n\\nBefore preprocessing X_train shape is:\"+str(X_train.shape))\n",
    "        print(\"Before preprocessing X_val shape is:\"+str(X_val.shape))\n",
    "\n",
    "        X_train = apply_preprocessing(X_train, preprocessing=signal_preprocessing)\n",
    "        X_val = apply_preprocessing(X_val, preprocessing=signal_preprocessing)\n",
    "        print(\"\\n\\nAfter preprocessing X_train shape is:\"+str(X_train.shape))\n",
    "        print(\"After preprocessing X_val shape is:\"+str(X_val.shape))\n",
    "\n",
    "\n",
    "        # Iteration over multiple runs\n",
    "        for train in range(n_train): # How many repetitions of training for subject i.\n",
    "            # Set the random seed for TensorFlow and NumPy random number generator.\n",
    "            # The purpose of setting a seed is to ensure reproducibility in random operations.\n",
    "            tf.random.set_seed(train+1)\n",
    "            np.random.seed(train+1)\n",
    "\n",
    "            # Get the current 'IN' time to calculate the 'run' training time\n",
    "            in_run = time.time()\n",
    "\n",
    "            # Create folders and files to save trained models for all runs\n",
    "            filepath = results_path + '/saved models/run-{}'.format(train+1)\n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            filepath = filepath + '/subject-{}.weights.h5'.format(sub+1)\n",
    "\n",
    "            # Create the model\n",
    "            model = getModel(model_name, dataset_conf, from_logits)\n",
    "            # Compile and train the model\n",
    "            model.compile(loss=CategoricalCrossentropy(from_logits=from_logits), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "            # model.summary()\n",
    "            # plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(filepath, monitor='val_loss', verbose=0,\n",
    "                                save_best_only=True, save_weights_only=True, mode='min'),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),\n",
    "                # EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\n",
    "            ]\n",
    "            history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot),\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=0)\n",
    "\n",
    "            # Evaluate the performance of the trained model based on the validation data\n",
    "            # Here we load the Trained weights from the file saved in the hard\n",
    "            # disk, which should be the same as the weights of the current model.\n",
    "            model.load_weights(filepath)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if from_logits:\n",
    "                y_pred = tf.nn.softmax(y_pred).numpy().argmax(axis=-1)\n",
    "            else:\n",
    "                y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "            labels = y_val_onehot.argmax(axis=-1)\n",
    "            acc[sub, train]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, train] = cohen_kappa_score(labels, y_pred)\n",
    "\n",
    "            # Get the current 'OUT' time to calculate the 'run' training time\n",
    "            out_run = time.time()\n",
    "            # Print & write performance measures for each run\n",
    "            info = 'Subject: {}   seed {}   time: {:.1f} m   '.format(sub+1, train+1, ((out_run-in_run)/60))\n",
    "            info = info + 'valid_acc: {:.4f}   valid_loss: {:.3f}'.format(acc[sub, train], min(history.history['val_loss']))\n",
    "            print(info)\n",
    "            log_write.write(info +'\\n')\n",
    "            # If current training run is better than previous runs, save the history.\n",
    "            if(BestSubjAcc < acc[sub, train]):\n",
    "                 BestSubjAcc = acc[sub, train]\n",
    "                 bestTrainingHistory = history\n",
    "\n",
    "        # Store the path of the best model among several runs\n",
    "        best_run = np.argmax(acc[sub,:])\n",
    "        filepath = '/saved models/run-{}/subject-{}.h5'.format(best_run+1, sub+1)+'\\n'\n",
    "        best_models.write(filepath)\n",
    "\n",
    "        # Plot Learning curves\n",
    "        if (LearnCurves == True):\n",
    "            print('Plot Learning Curves ....... ')\n",
    "            draw_learning_curves(bestTrainingHistory, sub+1)\n",
    "\n",
    "    # Get the current 'OUT' time to calculate the overall training time\n",
    "    out_exp = time.time()\n",
    "\n",
    "    # Print & write the validation performance using all seeds\n",
    "    head1 = head2 = '         '\n",
    "    for sub in range(n_sub):\n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n---------------------------------\\nValidation performance (acc %):'\n",
    "    info = info + '\\n---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(n_train):\n",
    "        info = info + '\\nSeed {}:  '.format(run+1)\n",
    "        for sub in range(n_sub):\n",
    "            info = info + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "        info = info + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "    info = info + '\\n---------------------------------\\nAverage acc - all seeds: '\n",
    "    info = info + '{:.2f} %\\n\\nTrain Time  - all seeds: {:.1f}'.format(np.average(acc)*100, (out_exp-in_exp)/(60))\n",
    "    info = info + ' min\\n---------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "\n",
    "    # Close open files\n",
    "    best_models.close()\n",
    "    log_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94bvHJeiVHbe"
   },
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "doqjxvQFVGeB"
   },
   "outputs": [],
   "source": [
    "#%% Evaluation\n",
    "def test(model, dataset_conf, results_path, allRuns = True):\n",
    "    # Open the  \"Log\" file to write the evaluation results\n",
    "    log_write = open(results_path + \"/log.txt\", \"a\")\n",
    "\n",
    "    # Get dataset paramters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    signal_preprocessing = dataset_conf.get('signal_preprocessing')\n",
    "    n_classes = dataset_conf.get('n_classes')\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    classes_labels = dataset_conf.get('cl_labels')\n",
    "    #Ripetuto\n",
    "    #signal_preprocessing = dataset_conf.get('signal_preprocessing')\n",
    "\n",
    "    # Test the performance based on several runs (seeds)\n",
    "    runs = os.listdir(results_path+\"/saved models\")\n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, len(runs)))\n",
    "    kappa = np.zeros((n_sub, len(runs)))\n",
    "    cf_matrix = np.zeros([n_sub, len(runs), n_classes, n_classes])\n",
    "\n",
    "    # Iteration over subjects\n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    inference_time = 0 #  inference_time: classification time for one trial\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "        # Load data\n",
    "        _, _, _, X_test, _, y_test_onehot = get_data(data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n",
    "\n",
    "        X_test = apply_preprocessing(X_test, preprocessing=signal_preprocessing)\n",
    "\n",
    "        # Iteration over runs (seeds)\n",
    "        for seed in range(len(runs)):\n",
    "            # Load the model of the seed.\n",
    "            model.load_weights('{}/saved models/{}/subject-{}.h5'.format(results_path, runs[seed], sub+1))\n",
    "\n",
    "            inference_time = time.time()\n",
    "            # Predict MI task\n",
    "            y_pred = model.predict(X_test).argmax(axis=-1)\n",
    "            inference_time = (time.time() - inference_time)/X_test.shape[0]\n",
    "            # Calculate accuracy and K-score\n",
    "            labels = y_test_onehot.argmax(axis=-1)\n",
    "            acc[sub, seed]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, seed] = cohen_kappa_score(labels, y_pred)\n",
    "            # Calculate and draw confusion matrix\n",
    "            cf_matrix[sub, seed, :, :] = confusion_matrix(labels, y_pred, normalize='true')\n",
    "            # draw_confusion_matrix(cf_matrix[sub, seed, :, :], str(sub+1), results_path, classes_labels)\n",
    "\n",
    "    # Print & write the average performance measures for all subjects\n",
    "    head1 = head2 = '                  '\n",
    "    for sub in range(n_sub):\n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n' + head1 +'\\n'+ head2\n",
    "    info = '\\n---------------------------------\\nTest performance (acc & k-score):\\n'\n",
    "    info = info + '---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(len(runs)):\n",
    "        info = info + '\\nSeed {}: '.format(run+1)\n",
    "        info_acc = '(acc %)   '\n",
    "        info_k = '        (k-sco)   '\n",
    "        for sub in range(n_sub):\n",
    "            info_acc = info_acc + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "            info_k = info_k + '{:.3f}   '.format(kappa[sub, run])\n",
    "        info_acc = info_acc + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "        info_k = info_k + '  {:.3f}   '.format(np.average(kappa[:, run]))\n",
    "        info = info + info_acc + '\\n' + info_k\n",
    "    info = info + '\\n----------------------------------\\nAverage - all seeds (acc %): '\n",
    "    info = info + '{:.2f}\\n                    (k-sco): '.format(np.average(acc)*100)\n",
    "    info = info + '{:.3f}\\n\\nInference time: {:.2f}'.format(np.average(kappa), inference_time * 1000)\n",
    "    info = info + ' ms per trial\\n----------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "\n",
    "    # Draw a performance bar chart for all subjects\n",
    "    draw_performance_barChart(n_sub, acc.mean(1), 'Accuracy')\n",
    "    draw_performance_barChart(n_sub, kappa.mean(1), 'k-score')\n",
    "    # Draw confusion matrix for all subjects (average)\n",
    "    draw_confusion_matrix(cf_matrix.mean((0,1)), 'All', results_path, classes_labels)\n",
    "    # Close opened file\n",
    "    log_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weCl_i-ZVdlL"
   },
   "source": [
    "# Model selection and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5gAM65lQSTH1"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "def getModel(model_name, dataset_conf, from_logits = False):\n",
    "\n",
    "    n_classes = dataset_conf.get('n_classes')\n",
    "    n_channels = dataset_conf.get('n_channels')\n",
    "    in_samples = dataset_conf.get('in_samples')\n",
    "\n",
    "    # Select the model\n",
    "    if(model_name == 'RockNet'):\n",
    "        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n",
    "        model = models.RockNet_(\n",
    "            # Dataset parameters\n",
    "            n_classes = n_classes,\n",
    "            in_chans = n_channels,\n",
    "            in_samples = in_samples,\n",
    "            # Sliding window (SW) parameter\n",
    "            n_windows = 5,\n",
    "            # Attention (AT) block parameter\n",
    "            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n",
    "            # Convolutional (CV) block parameters\n",
    "            eegn_F1 = 16,\n",
    "            eegn_D = 2,\n",
    "            eegn_kernelSize = 64,\n",
    "            eegn_poolSize = 7,\n",
    "            eegn_dropout = 0.5,\n",
    "            # Temporal convolutional (TC) block parameters\n",
    "            tcn_depth = 2,\n",
    "            tcn_kernelSize = 4,\n",
    "            tcn_filters = 64,\n",
    "            tcn_dropout = 0.3,\n",
    "            tcn_activation='elu',\n",
    "            )\n",
    "    elif(model_name == 'ATCNet'):\n",
    "        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n",
    "        model = models.ATCNet_(\n",
    "            # Dataset parameters\n",
    "            n_classes = n_classes,\n",
    "            in_chans = n_channels,\n",
    "            in_samples = in_samples,\n",
    "            # Sliding window (SW) parameter\n",
    "            n_windows = 5,\n",
    "            # Attention (AT) block parameter\n",
    "            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n",
    "            # Convolutional (CV) block parameters\n",
    "            eegn_F1 = 16,\n",
    "            eegn_D = 2,\n",
    "            eegn_kernelSize = 64,\n",
    "            eegn_poolSize = 7,\n",
    "            eegn_dropout = 0.3,\n",
    "            # Temporal convolutional (TC) block parameters\n",
    "            tcn_depth = 2,\n",
    "            tcn_kernelSize = 4,\n",
    "            tcn_filters = 32,\n",
    "            tcn_dropout = 0.3,\n",
    "            tcn_activation='elu',\n",
    "            )\n",
    "    elif(model_name == 'TCNet_Fusion'):\n",
    "        # Train using TCNet_Fusion: https://doi.org/10.1016/j.bspc.2021.102826\n",
    "        model = models.TCNet_Fusion(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n",
    "    elif(model_name == 'EEGTCNet'):\n",
    "        # Train using EEGTCNet: https://arxiv.org/abs/2006.00622\n",
    "        model = models.EEGTCNet(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n",
    "    elif(model_name == 'EEGNet'):\n",
    "        # Train using EEGNet: https://arxiv.org/abs/1611.08024\n",
    "        model = models.EEGNet_classifier(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n",
    "    elif(model_name == 'EEGNeX'):\n",
    "        # Train using EEGNeX: https://arxiv.org/abs/2207.12369\n",
    "        model = models.EEGNeX_8_32(n_timesteps = in_samples , n_features = n_channels, n_outputs = n_classes)\n",
    "    elif(model_name == 'DeepConvNet'):\n",
    "        # Train using DeepConvNet: https://doi.org/10.1002/hbm.23730\n",
    "        model = models.DeepConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    elif(model_name == 'ShallowConvNet'):\n",
    "        # Train using ShallowConvNet: https://doi.org/10.1002/hbm.23730\n",
    "        model = models.ShallowConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    elif(model_name == 'MBEEG_SENet'):\n",
    "        # Train using MBEEG_SENet: https://www.mdpi.com/2075-4418/12/4/995\n",
    "        model = models.MBEEG_SENet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"'{}' model is not supported yet!\".format(model_name))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE_qndEAVZ-_"
   },
   "source": [
    "# Run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkiYgl7FDPqN"
   },
   "source": [
    "## Define the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nWF0BbQzVbdN"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "def run(signal_preprocessing):\n",
    "    # Define dataset parameters\n",
    "    #dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n",
    "    dataset = 'HGD'\n",
    "\n",
    "    if dataset == 'BCI2a':\n",
    "        in_samples = 1125\n",
    "        n_channels = 22\n",
    "        n_sub = 9\n",
    "        n_classes = 4\n",
    "        classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "        data_path = 'dataset/' #os.path.expanduser('~') + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n",
    "    elif dataset == 'HGD':\n",
    "        #print(\"Dataset scelto:\",dataset)\n",
    "        in_samples = 1125\n",
    "        n_channels = 44\n",
    "        n_sub = 14\n",
    "        n_classes = 4\n",
    "        classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']\n",
    "        data_path = 'dataset/' #os.path.expanduser('~') + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n",
    "        #print(\"Data path:\",data_path)\n",
    "    elif dataset == 'CS2R':\n",
    "        in_samples = 1125\n",
    "        # in_samples = 576\n",
    "        n_channels = 32\n",
    "        n_sub = 18\n",
    "        n_classes = 3\n",
    "        # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']\n",
    "        classes_labels = ['Fingers', 'Wrist','Elbow']\n",
    "        # classes_labels = ['Fingers', 'Elbow']\n",
    "        data_path = os.path.expanduser('~') + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n",
    "    else:\n",
    "        raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "\n",
    "    # Create a folder to store the results of the experiment\n",
    "    results_path = os.getcwd() + \"/results\"\n",
    "    if not  os.path.exists(results_path):\n",
    "      os.makedirs(results_path)   # Create a new directory if it does not exist\n",
    "\n",
    "    # Set dataset paramters\n",
    "    dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                    'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                    'data_path': data_path, 'isStandard': True, 'LOSO': False,\n",
    "                     'signal_preprocessing':signal_preprocessing}\n",
    "\n",
    "    # Set training hyperparamters\n",
    "    train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                  'LearnCurves': True, 'from_logits': False, 'model':'RockNet'}\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training the model...\")\n",
    "    train(dataset_conf, train_conf, results_path)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    # Evaluate the model based on the weights saved in the '/results' folder\n",
    "    model = getModel(train_conf.get('model'), dataset_conf)\n",
    "    test(model, dataset_conf, results_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKAI_oyNBGVd"
   },
   "source": [
    "## No preprocessing on EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "-8J-ZBUXCr-3",
    "outputId": "1ea1b7f4-601f-44b0-b349-d499ea12143d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Dataset:  HGD\n",
      "Number of subjects:  14\n",
      "Data path:  dataset/\n",
      "Standardization:  True\n",
      "Leave-one-subject-out:  False\n",
      "\n",
      "Training on subject  1\n",
      "Sto per chiamare get_data\n",
      "Creating RawArray with float64 data, n_channels=128, n_times=1225545\n",
      "    Range : 0 ... 1225544 =      0.000 ...  2451.088 secs\n",
      "Ready.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Dati grezzi CST_raw_mne: (129, 1225545)\n",
      "Canali di stimolazione trovati: ['STI 014']\n",
      "320 events found on stim channel STI 014\n",
      "Event IDs: [2 4 6 8]\n",
      "Eventi estratti: [[   5001       0       6]\n",
      " [   8726       0       8]\n",
      " [  12236       0       4]\n",
      " [  15941       0       2]\n",
      " [  19731       0       6]\n",
      " [  23276       0       2]\n",
      " [  26901       0       8]\n",
      " [  30551       0       4]\n",
      " [  34106       0       2]\n",
      " [  37921       0       6]\n",
      " [  41581       0       4]\n",
      " [  45571       0       8]\n",
      " [  49536       0       4]\n",
      " [  53366       0       8]\n",
      " [  57191       0       6]\n",
      " [  60946       0       2]\n",
      " [  64796       0       2]\n",
      " [  68326       0       8]\n",
      " [  72191       0       6]\n",
      " [  76056       0       4]\n",
      " [  79641       0       6]\n",
      " [  83536       0       8]\n",
      " [  87056       0       4]\n",
      " [  90906       0       2]\n",
      " [  94461       0       6]\n",
      " [  98251       0       2]\n",
      " [ 102016       0       4]\n",
      " [ 105871       0       8]\n",
      " [ 109456       0       8]\n",
      " [ 113331       0       6]\n",
      " [ 116831       0       2]\n",
      " [ 120711       0       4]\n",
      " [ 124516       0       8]\n",
      " [ 128061       0       4]\n",
      " [ 131671       0       2]\n",
      " [ 135206       0       6]\n",
      " [ 138826       0       2]\n",
      " [ 142661       0       6]\n",
      " [ 146431       0       8]\n",
      " [ 149971       0       4]\n",
      " [ 153521       0       8]\n",
      " [ 157436       0       4]\n",
      " [ 161036       0       2]\n",
      " [ 164981       0       6]\n",
      " [ 168831       0       6]\n",
      " [ 172761       0       4]\n",
      " [ 176731       0       8]\n",
      " [ 180316       0       2]\n",
      " [ 184166       0       8]\n",
      " [ 187726       0       6]\n",
      " [ 191336       0       2]\n",
      " [ 194846       0       4]\n",
      " [ 198716       0       6]\n",
      " [ 202501       0       2]\n",
      " [ 206201       0       8]\n",
      " [ 209831       0       4]\n",
      " [ 213521       0       2]\n",
      " [ 217426       0       8]\n",
      " [ 221266       0       4]\n",
      " [ 224796       0       6]\n",
      " [ 228591       0       8]\n",
      " [ 232301       0       6]\n",
      " [ 236031       0       4]\n",
      " [ 239566       0       2]\n",
      " [ 243151       0       4]\n",
      " [ 246676       0       8]\n",
      " [ 250536       0       2]\n",
      " [ 254196       0       6]\n",
      " [ 257721       0       2]\n",
      " [ 261396       0       4]\n",
      " [ 265026       0       8]\n",
      " [ 268806       0       6]\n",
      " [ 272541       0       4]\n",
      " [ 276526       0       8]\n",
      " [ 280101       0       2]\n",
      " [ 284046       0       6]\n",
      " [ 287666       0       2]\n",
      " [ 291226       0       8]\n",
      " [ 295031       0       6]\n",
      " [ 298911       0       4]\n",
      " [ 310316       0       4]\n",
      " [ 314041       0       6]\n",
      " [ 317641       0       2]\n",
      " [ 321626       0       8]\n",
      " [ 325581       0       8]\n",
      " [ 329206       0       2]\n",
      " [ 333181       0       6]\n",
      " [ 336736       0       4]\n",
      " [ 340696       0       8]\n",
      " [ 344266       0       6]\n",
      " [ 348051       0       4]\n",
      " [ 351991       0       2]\n",
      " [ 355611       0       6]\n",
      " [ 359466       0       4]\n",
      " [ 363086       0       8]\n",
      " [ 366961       0       2]\n",
      " [ 370536       0       4]\n",
      " [ 374041       0       8]\n",
      " [ 377606       0       2]\n",
      " [ 381316       0       6]\n",
      " [ 384911       0       8]\n",
      " [ 388761       0       2]\n",
      " [ 392426       0       4]\n",
      " [ 396361       0       6]\n",
      " [ 399956       0       6]\n",
      " [ 403656       0       4]\n",
      " [ 407291       0       8]\n",
      " [ 410961       0       2]\n",
      " [ 414571       0       8]\n",
      " [ 418146       0       6]\n",
      " [ 421646       0       4]\n",
      " [ 425261       0       2]\n",
      " [ 428921       0       8]\n",
      " [ 432786       0       6]\n",
      " [ 436676       0       2]\n",
      " [ 440556       0       4]\n",
      " [ 444231       0       6]\n",
      " [ 447791       0       2]\n",
      " [ 451311       0       8]\n",
      " [ 455246       0       4]\n",
      " [ 458916       0       6]\n",
      " [ 462671       0       2]\n",
      " [ 466531       0       8]\n",
      " [ 470436       0       4]\n",
      " [ 474036       0       4]\n",
      " [ 477771       0       2]\n",
      " [ 481431       0       8]\n",
      " [ 485031       0       6]\n",
      " [ 488851       0       4]\n",
      " [ 492476       0       6]\n",
      " [ 496146       0       2]\n",
      " [ 500006       0       8]\n",
      " [ 503821       0       6]\n",
      " [ 507531       0       8]\n",
      " [ 511526       0       4]\n",
      " [ 515281       0       2]\n",
      " [ 519196       0       4]\n",
      " [ 522766       0       6]\n",
      " [ 526291       0       2]\n",
      " [ 529851       0       8]\n",
      " [ 533766       0       6]\n",
      " [ 537726       0       2]\n",
      " [ 541586       0       8]\n",
      " [ 545376       0       4]\n",
      " [ 549356       0       4]\n",
      " [ 553141       0       2]\n",
      " [ 556851       0       6]\n",
      " [ 560696       0       8]\n",
      " [ 564271       0       6]\n",
      " [ 568151       0       8]\n",
      " [ 571666       0       4]\n",
      " [ 575601       0       2]\n",
      " [ 579221       0       6]\n",
      " [ 582916       0       8]\n",
      " [ 586551       0       2]\n",
      " [ 590101       0       4]\n",
      " [ 593776       0       4]\n",
      " [ 597571       0       8]\n",
      " [ 601411       0       2]\n",
      " [ 605296       0       6]\n",
      " [ 616526       0       2]\n",
      " [ 620151       0       8]\n",
      " [ 624106       0       4]\n",
      " [ 627676       0       6]\n",
      " [ 631601       0       2]\n",
      " [ 635386       0       6]\n",
      " [ 638911       0       8]\n",
      " [ 642466       0       4]\n",
      " [ 646151       0       2]\n",
      " [ 650081       0       4]\n",
      " [ 653656       0       6]\n",
      " [ 657276       0       8]\n",
      " [ 660781       0       2]\n",
      " [ 664296       0       8]\n",
      " [ 667871       0       4]\n",
      " [ 671531       0       6]\n",
      " [ 675221       0       8]\n",
      " [ 679171       0       2]\n",
      " [ 682911       0       6]\n",
      " [ 686841       0       4]\n",
      " [ 690826       0       2]\n",
      " [ 694676       0       6]\n",
      " [ 698221       0       4]\n",
      " [ 701771       0       8]\n",
      " [ 705291       0       6]\n",
      " [ 708911       0       8]\n",
      " [ 712446       0       4]\n",
      " [ 716406       0       2]\n",
      " [ 720046       0       8]\n",
      " [ 723706       0       4]\n",
      " [ 727346       0       2]\n",
      " [ 731316       0       6]\n",
      " [ 735266       0       4]\n",
      " [ 739231       0       6]\n",
      " [ 742821       0       2]\n",
      " [ 746431       0       8]\n",
      " [ 750226       0       8]\n",
      " [ 754041       0       6]\n",
      " [ 758021       0       2]\n",
      " [ 761666       0       4]\n",
      " [ 765411       0       6]\n",
      " [ 768996       0       8]\n",
      " [ 772781       0       2]\n",
      " [ 776376       0       4]\n",
      " [ 780291       0       4]\n",
      " [ 783831       0       2]\n",
      " [ 787431       0       8]\n",
      " [ 790961       0       6]\n",
      " [ 794471       0       2]\n",
      " [ 798326       0       6]\n",
      " [ 802086       0       8]\n",
      " [ 805791       0       4]\n",
      " [ 809596       0       2]\n",
      " [ 813191       0       8]\n",
      " [ 816911       0       4]\n",
      " [ 820821       0       6]\n",
      " [ 824786       0       6]\n",
      " [ 828441       0       8]\n",
      " [ 832156       0       4]\n",
      " [ 835681       0       2]\n",
      " [ 839491       0       4]\n",
      " [ 843471       0       6]\n",
      " [ 847266       0       2]\n",
      " [ 851156       0       8]\n",
      " [ 854916       0       2]\n",
      " [ 858831       0       4]\n",
      " [ 862806       0       6]\n",
      " [ 866336       0       8]\n",
      " [ 869876       0       2]\n",
      " [ 873746       0       4]\n",
      " [ 877611       0       8]\n",
      " [ 881476       0       6]\n",
      " [ 885396       0       2]\n",
      " [ 889076       0       4]\n",
      " [ 892896       0       8]\n",
      " [ 896451       0       6]\n",
      " [ 900096       0       6]\n",
      " [ 903811       0       8]\n",
      " [ 907451       0       4]\n",
      " [ 911271       0       2]\n",
      " [ 922446       0       6]\n",
      " [ 926351       0       2]\n",
      " [ 930071       0       4]\n",
      " [ 934051       0       8]\n",
      " [ 937811       0       4]\n",
      " [ 941431       0       8]\n",
      " [ 944931       0       6]\n",
      " [ 948721       0       2]\n",
      " [ 952511       0       2]\n",
      " [ 956496       0       6]\n",
      " [ 960076       0       8]\n",
      " [ 963651       0       4]\n",
      " [ 967341       0       2]\n",
      " [ 971016       0       4]\n",
      " [ 974666       0       6]\n",
      " [ 978296       0       8]\n",
      " [ 982026       0       2]\n",
      " [ 985681       0       6]\n",
      " [ 989231       0       8]\n",
      " [ 992956       0       4]\n",
      " [ 996611       0       2]\n",
      " [1000226       0       8]\n",
      " [1004111       0       6]\n",
      " [1007631       0       4]\n",
      " [1011181       0       8]\n",
      " [1015031       0       2]\n",
      " [1018726       0       4]\n",
      " [1022696       0       6]\n",
      " [1026341       0       6]\n",
      " [1030176       0       8]\n",
      " [1033811       0       2]\n",
      " [1037541       0       4]\n",
      " [1041106       0       2]\n",
      " [1044931       0       6]\n",
      " [1048881       0       4]\n",
      " [1052666       0       8]\n",
      " [1056526       0       6]\n",
      " [1060476       0       4]\n",
      " [1064351       0       2]\n",
      " [1068341       0       8]\n",
      " [1071961       0       8]\n",
      " [1075796       0       4]\n",
      " [1079481       0       6]\n",
      " [1083436       0       2]\n",
      " [1087201       0       2]\n",
      " [1090766       0       4]\n",
      " [1094346       0       8]\n",
      " [1098176       0       6]\n",
      " [1102126       0       2]\n",
      " [1105831       0       4]\n",
      " [1109761       0       8]\n",
      " [1113331       0       6]\n",
      " [1116851       0       2]\n",
      " [1120791       0       4]\n",
      " [1124651       0       6]\n",
      " [1128186       0       8]\n",
      " [1131986       0       4]\n",
      " [1135816       0       8]\n",
      " [1139806       0       6]\n",
      " [1143546       0       2]\n",
      " [1147166       0       8]\n",
      " [1150686       0       6]\n",
      " [1154631       0       2]\n",
      " [1158461       0       4]\n",
      " [1162371       0       2]\n",
      " [1165921       0       4]\n",
      " [1169636       0       6]\n",
      " [1173556       0       8]\n",
      " [1177396       0       6]\n",
      " [1181356       0       8]\n",
      " [1185221       0       4]\n",
      " [1188811       0       2]\n",
      " [1192471       0       8]\n",
      " [1196456       0       4]\n",
      " [1200196       0       6]\n",
      " [1204091       0       2]\n",
      " [1208046       0       6]\n",
      " [1211991       0       8]\n",
      " [1215546       0       2]\n",
      " [1219431       0       4]]\n",
      "Eventi filtrati: [array([5001,    0,    6]), array([8726,    0,    8]), array([12236,     0,     4]), array([15941,     0,     2]), array([19731,     0,     6]), array([23276,     0,     2]), array([26901,     0,     8]), array([30551,     0,     4]), array([34106,     0,     2]), array([37921,     0,     6]), array([41581,     0,     4]), array([45571,     0,     8]), array([49536,     0,     4]), array([53366,     0,     8]), array([57191,     0,     6]), array([60946,     0,     2]), array([64796,     0,     2]), array([68326,     0,     8]), array([72191,     0,     6]), array([76056,     0,     4]), array([79641,     0,     6]), array([83536,     0,     8]), array([87056,     0,     4]), array([90906,     0,     2]), array([94461,     0,     6]), array([98251,     0,     2]), array([102016,      0,      4]), array([105871,      0,      8]), array([109456,      0,      8]), array([113331,      0,      6]), array([116831,      0,      2]), array([120711,      0,      4]), array([124516,      0,      8]), array([128061,      0,      4]), array([131671,      0,      2]), array([135206,      0,      6]), array([138826,      0,      2]), array([142661,      0,      6]), array([146431,      0,      8]), array([149971,      0,      4]), array([153521,      0,      8]), array([157436,      0,      4]), array([161036,      0,      2]), array([164981,      0,      6]), array([168831,      0,      6]), array([172761,      0,      4]), array([176731,      0,      8]), array([180316,      0,      2]), array([184166,      0,      8]), array([187726,      0,      6]), array([191336,      0,      2]), array([194846,      0,      4]), array([198716,      0,      6]), array([202501,      0,      2]), array([206201,      0,      8]), array([209831,      0,      4]), array([213521,      0,      2]), array([217426,      0,      8]), array([221266,      0,      4]), array([224796,      0,      6]), array([228591,      0,      8]), array([232301,      0,      6]), array([236031,      0,      4]), array([239566,      0,      2]), array([243151,      0,      4]), array([246676,      0,      8]), array([250536,      0,      2]), array([254196,      0,      6]), array([257721,      0,      2]), array([261396,      0,      4]), array([265026,      0,      8]), array([268806,      0,      6]), array([272541,      0,      4]), array([276526,      0,      8]), array([280101,      0,      2]), array([284046,      0,      6]), array([287666,      0,      2]), array([291226,      0,      8]), array([295031,      0,      6]), array([298911,      0,      4]), array([310316,      0,      4]), array([314041,      0,      6]), array([317641,      0,      2]), array([321626,      0,      8]), array([325581,      0,      8]), array([329206,      0,      2]), array([333181,      0,      6]), array([336736,      0,      4]), array([340696,      0,      8]), array([344266,      0,      6]), array([348051,      0,      4]), array([351991,      0,      2]), array([355611,      0,      6]), array([359466,      0,      4]), array([363086,      0,      8]), array([366961,      0,      2]), array([370536,      0,      4]), array([374041,      0,      8]), array([377606,      0,      2]), array([381316,      0,      6]), array([384911,      0,      8]), array([388761,      0,      2]), array([392426,      0,      4]), array([396361,      0,      6]), array([399956,      0,      6]), array([403656,      0,      4]), array([407291,      0,      8]), array([410961,      0,      2]), array([414571,      0,      8]), array([418146,      0,      6]), array([421646,      0,      4]), array([425261,      0,      2]), array([428921,      0,      8]), array([432786,      0,      6]), array([436676,      0,      2]), array([440556,      0,      4]), array([444231,      0,      6]), array([447791,      0,      2]), array([451311,      0,      8]), array([455246,      0,      4]), array([458916,      0,      6]), array([462671,      0,      2]), array([466531,      0,      8]), array([470436,      0,      4]), array([474036,      0,      4]), array([477771,      0,      2]), array([481431,      0,      8]), array([485031,      0,      6]), array([488851,      0,      4]), array([492476,      0,      6]), array([496146,      0,      2]), array([500006,      0,      8]), array([503821,      0,      6]), array([507531,      0,      8]), array([511526,      0,      4]), array([515281,      0,      2]), array([519196,      0,      4]), array([522766,      0,      6]), array([526291,      0,      2]), array([529851,      0,      8]), array([533766,      0,      6]), array([537726,      0,      2]), array([541586,      0,      8]), array([545376,      0,      4]), array([549356,      0,      4]), array([553141,      0,      2]), array([556851,      0,      6]), array([560696,      0,      8]), array([564271,      0,      6]), array([568151,      0,      8]), array([571666,      0,      4]), array([575601,      0,      2]), array([579221,      0,      6]), array([582916,      0,      8]), array([586551,      0,      2]), array([590101,      0,      4]), array([593776,      0,      4]), array([597571,      0,      8]), array([601411,      0,      2]), array([605296,      0,      6]), array([616526,      0,      2]), array([620151,      0,      8]), array([624106,      0,      4]), array([627676,      0,      6]), array([631601,      0,      2]), array([635386,      0,      6]), array([638911,      0,      8]), array([642466,      0,      4]), array([646151,      0,      2]), array([650081,      0,      4]), array([653656,      0,      6]), array([657276,      0,      8]), array([660781,      0,      2]), array([664296,      0,      8]), array([667871,      0,      4]), array([671531,      0,      6]), array([675221,      0,      8]), array([679171,      0,      2]), array([682911,      0,      6]), array([686841,      0,      4]), array([690826,      0,      2]), array([694676,      0,      6]), array([698221,      0,      4]), array([701771,      0,      8]), array([705291,      0,      6]), array([708911,      0,      8]), array([712446,      0,      4]), array([716406,      0,      2]), array([720046,      0,      8]), array([723706,      0,      4]), array([727346,      0,      2]), array([731316,      0,      6]), array([735266,      0,      4]), array([739231,      0,      6]), array([742821,      0,      2]), array([746431,      0,      8]), array([750226,      0,      8]), array([754041,      0,      6]), array([758021,      0,      2]), array([761666,      0,      4]), array([765411,      0,      6]), array([768996,      0,      8]), array([772781,      0,      2]), array([776376,      0,      4]), array([780291,      0,      4]), array([783831,      0,      2]), array([787431,      0,      8]), array([790961,      0,      6]), array([794471,      0,      2]), array([798326,      0,      6]), array([802086,      0,      8]), array([805791,      0,      4]), array([809596,      0,      2]), array([813191,      0,      8]), array([816911,      0,      4]), array([820821,      0,      6]), array([824786,      0,      6]), array([828441,      0,      8]), array([832156,      0,      4]), array([835681,      0,      2]), array([839491,      0,      4]), array([843471,      0,      6]), array([847266,      0,      2]), array([851156,      0,      8]), array([854916,      0,      2]), array([858831,      0,      4]), array([862806,      0,      6]), array([866336,      0,      8]), array([869876,      0,      2]), array([873746,      0,      4]), array([877611,      0,      8]), array([881476,      0,      6]), array([885396,      0,      2]), array([889076,      0,      4]), array([892896,      0,      8]), array([896451,      0,      6]), array([900096,      0,      6]), array([903811,      0,      8]), array([907451,      0,      4]), array([911271,      0,      2]), array([922446,      0,      6]), array([926351,      0,      2]), array([930071,      0,      4]), array([934051,      0,      8]), array([937811,      0,      4]), array([941431,      0,      8]), array([944931,      0,      6]), array([948721,      0,      2]), array([952511,      0,      2]), array([956496,      0,      6]), array([960076,      0,      8]), array([963651,      0,      4]), array([967341,      0,      2]), array([971016,      0,      4]), array([974666,      0,      6]), array([978296,      0,      8]), array([982026,      0,      2]), array([985681,      0,      6]), array([989231,      0,      8]), array([992956,      0,      4]), array([996611,      0,      2]), array([1000226,       0,       8]), array([1004111,       0,       6]), array([1007631,       0,       4]), array([1011181,       0,       8]), array([1015031,       0,       2]), array([1018726,       0,       4]), array([1022696,       0,       6]), array([1026341,       0,       6]), array([1030176,       0,       8]), array([1033811,       0,       2]), array([1037541,       0,       4]), array([1041106,       0,       2]), array([1044931,       0,       6]), array([1048881,       0,       4]), array([1052666,       0,       8]), array([1056526,       0,       6]), array([1060476,       0,       4]), array([1064351,       0,       2]), array([1068341,       0,       8]), array([1071961,       0,       8]), array([1075796,       0,       4]), array([1079481,       0,       6]), array([1083436,       0,       2]), array([1087201,       0,       2]), array([1090766,       0,       4]), array([1094346,       0,       8]), array([1098176,       0,       6]), array([1102126,       0,       2]), array([1105831,       0,       4]), array([1109761,       0,       8]), array([1113331,       0,       6]), array([1116851,       0,       2]), array([1120791,       0,       4]), array([1124651,       0,       6]), array([1128186,       0,       8]), array([1131986,       0,       4]), array([1135816,       0,       8]), array([1139806,       0,       6]), array([1143546,       0,       2]), array([1147166,       0,       8]), array([1150686,       0,       6]), array([1154631,       0,       2]), array([1158461,       0,       4]), array([1162371,       0,       2]), array([1165921,       0,       4]), array([1169636,       0,       6]), array([1173556,       0,       8]), array([1177396,       0,       6]), array([1181356,       0,       8]), array([1185221,       0,       4]), array([1188811,       0,       2]), array([1192471,       0,       8]), array([1196456,       0,       4]), array([1200196,       0,       6]), array([1204091,       0,       2]), array([1208046,       0,       6]), array([1211991,       0,       8]), array([1215546,       0,       2]), array([1219431,       0,       4])]\n",
      "Dati del canale 'STI 014': [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Intervallo epoca: [0, 4000]\n",
      "Codici di inizio: OrderedDict([('Right Hand', [2]), ('Left Hand', [4]), ('Rest', [6]), ('Feet', [8])])\n",
      "Dati in create_signal_target: (129, 1225545)\n",
      "Eventi:  320\n",
      "DEBUG--CREATE_SIGNAL_TARGET_FROM_START_AND_IVAL\n",
      "Dati in _create_signal_target_from_start_and_ival: (129, 1225545)\n",
      "Eventi: 320\n",
      "mrk_code_to_name_and_y: {2: ('Right Hand', 0), 4: ('Left Hand', 1), 6: ('Rest', 2), 8: ('Feet', 3)}\n",
      "events len: 320\n",
      "Prime righe di events: [array([5001,    0,    6]), array([8726,    0,    8]), array([12236,     0,     4]), array([15941,     0,     2]), array([19731,     0,     6]), array([23276,     0,     2]), array([26901,     0,     8]), array([30551,     0,     4]), array([34106,     0,     2]), array([37921,     0,     6])]\n",
      "Tipi di dati in events[:, 0]: {780291, 503821, 1007631, 866336, 1030176, 735266, 135206, 1083436, 276526, 989231, 1173556, 198716, 1200196, 616526, 956496, 221266, 321626, 180316, 116831, 835681, 575601, 53366, 295031, 813191, 481431, 272541, 934051, 458916, 731316, 553141, 776376, 1079481, 907451, 952511, 403656, 317641, 344266, 667871, 1169636, 440556, 254196, 889076, 94461, 758021, 971016, 571666, 26901, 590101, 930071, 76056, 194846, 1147166, 1026341, 500006, 1124651, 1102126, 708911, 1048881, 727346, 217426, 653656, 418146, 366961, 754041, 49536, 381316, 694676, 291226, 1196456, 790961, 1098176, 1044931, 436676, 149971, 549356, 948721, 635386, 72191, 236031, 45571, 268806, 522766, 213521, 496146, 8726, 1120791, 1192471, 477771, 363086, 1004111, 455246, 985681, 399956, 1075796, 862806, 131671, 176731, 545376, 1165921, 41581, 809596, 903811, 690826, 926351, 432786, 750226, 885396, 832156, 250536, 772781, 967341, 113331, 1116851, 314041, 1094346, 858831, 1041106, 340696, 172761, 68326, 664296, 1022696, 23276, 451311, 686841, 723706, 1143546, 377606, 705291, 90906, 1000226, 944931, 631601, 586551, 265026, 881476, 922446, 568151, 1071961, 336736, 650081, 1018726, 1219431, 191336, 414571, 232301, 428921, 168831, 854916, 5001, 109456, 541586, 246676, 682911, 805791, 209831, 287666, 474036, 492476, 746431, 1188811, 627676, 768996, 787431, 146431, 900096, 646151, 982026, 87056, 828441, 519196, 37921, 359466, 877611, 310316, 564271, 1215546, 128061, 963651, 396361, 1139806, 605296, 164981, 537726, 1162371, 720046, 1135816, 1090766, 515281, 851156, 1037541, 392426, 228591, 1113331, 1015031, 679171, 582916, 996611, 533766, 161036, 873746, 19731, 261396, 374041, 355611, 64796, 802086, 425261, 660781, 447791, 1068341, 34106, 1158461, 601411, 142661, 701771, 187726, 410961, 941431, 978296, 206201, 333181, 284046, 105871, 488851, 675221, 1064351, 642466, 847266, 470436, 742821, 529851, 896451, 1185221, 243151, 824786, 1131986, 783831, 765411, 624106, 1011181, 869876, 329206, 60946, 224796, 280101, 511526, 560696, 597571, 15941, 1154631, 138826, 960076, 83536, 1033811, 820821, 1211991, 466531, 124516, 716406, 620151, 798326, 1060476, 102016, 507531, 579221, 388761, 485031, 1181356, 257721, 992956, 843471, 1150686, 1087201, 1208046, 351991, 1128186, 407291, 157436, 712446, 1109761, 202501, 421646, 816911, 1056526, 79641, 671531, 556851, 1177396, 761666, 839491, 444231, 974666, 462671, 937811, 30551, 184166, 57191, 370536, 794471, 698221, 593776, 1204091, 657276, 120711, 384911, 348051, 298911, 739231, 911271, 1105831, 153521, 638911, 98251, 12236, 325581, 239566, 526291, 892896, 1052666}\n",
      "Tipi di dati in events[:, 2]: {8, 2, 4, 6}\n",
      "Processing trial: mrk_code=6, start_sample=5001, stop_sample=7001\n",
      "Processing trial: mrk_code=8, start_sample=8726, stop_sample=10726\n",
      "Processing trial: mrk_code=4, start_sample=12236, stop_sample=14236\n",
      "Processing trial: mrk_code=2, start_sample=15941, stop_sample=17941\n",
      "Processing trial: mrk_code=6, start_sample=19731, stop_sample=21731\n",
      "Processing trial: mrk_code=2, start_sample=23276, stop_sample=25276\n",
      "Processing trial: mrk_code=8, start_sample=26901, stop_sample=28901\n",
      "Processing trial: mrk_code=4, start_sample=30551, stop_sample=32551\n",
      "Processing trial: mrk_code=2, start_sample=34106, stop_sample=36106\n",
      "Processing trial: mrk_code=6, start_sample=37921, stop_sample=39921\n",
      "Processing trial: mrk_code=4, start_sample=41581, stop_sample=43581\n",
      "Processing trial: mrk_code=8, start_sample=45571, stop_sample=47571\n",
      "Processing trial: mrk_code=4, start_sample=49536, stop_sample=51536\n",
      "Processing trial: mrk_code=8, start_sample=53366, stop_sample=55366\n",
      "Processing trial: mrk_code=6, start_sample=57191, stop_sample=59191\n",
      "Processing trial: mrk_code=2, start_sample=60946, stop_sample=62946\n",
      "Processing trial: mrk_code=2, start_sample=64796, stop_sample=66796\n",
      "Processing trial: mrk_code=8, start_sample=68326, stop_sample=70326\n",
      "Processing trial: mrk_code=6, start_sample=72191, stop_sample=74191\n",
      "Processing trial: mrk_code=4, start_sample=76056, stop_sample=78056\n",
      "Processing trial: mrk_code=6, start_sample=79641, stop_sample=81641\n",
      "Processing trial: mrk_code=8, start_sample=83536, stop_sample=85536\n",
      "Processing trial: mrk_code=4, start_sample=87056, stop_sample=89056\n",
      "Processing trial: mrk_code=2, start_sample=90906, stop_sample=92906\n",
      "Processing trial: mrk_code=6, start_sample=94461, stop_sample=96461\n",
      "Processing trial: mrk_code=2, start_sample=98251, stop_sample=100251\n",
      "Processing trial: mrk_code=4, start_sample=102016, stop_sample=104016\n",
      "Processing trial: mrk_code=8, start_sample=105871, stop_sample=107871\n",
      "Processing trial: mrk_code=8, start_sample=109456, stop_sample=111456\n",
      "Processing trial: mrk_code=6, start_sample=113331, stop_sample=115331\n",
      "Processing trial: mrk_code=2, start_sample=116831, stop_sample=118831\n",
      "Processing trial: mrk_code=4, start_sample=120711, stop_sample=122711\n",
      "Processing trial: mrk_code=8, start_sample=124516, stop_sample=126516\n",
      "Processing trial: mrk_code=4, start_sample=128061, stop_sample=130061\n",
      "Processing trial: mrk_code=2, start_sample=131671, stop_sample=133671\n",
      "Processing trial: mrk_code=6, start_sample=135206, stop_sample=137206\n",
      "Processing trial: mrk_code=2, start_sample=138826, stop_sample=140826\n",
      "Processing trial: mrk_code=6, start_sample=142661, stop_sample=144661\n",
      "Processing trial: mrk_code=8, start_sample=146431, stop_sample=148431\n",
      "Processing trial: mrk_code=4, start_sample=149971, stop_sample=151971\n",
      "Processing trial: mrk_code=8, start_sample=153521, stop_sample=155521\n",
      "Processing trial: mrk_code=4, start_sample=157436, stop_sample=159436\n",
      "Processing trial: mrk_code=2, start_sample=161036, stop_sample=163036\n",
      "Processing trial: mrk_code=6, start_sample=164981, stop_sample=166981\n",
      "Processing trial: mrk_code=6, start_sample=168831, stop_sample=170831\n",
      "Processing trial: mrk_code=4, start_sample=172761, stop_sample=174761\n",
      "Processing trial: mrk_code=8, start_sample=176731, stop_sample=178731\n",
      "Processing trial: mrk_code=2, start_sample=180316, stop_sample=182316\n",
      "Processing trial: mrk_code=8, start_sample=184166, stop_sample=186166\n",
      "Processing trial: mrk_code=6, start_sample=187726, stop_sample=189726\n",
      "Processing trial: mrk_code=2, start_sample=191336, stop_sample=193336\n",
      "Processing trial: mrk_code=4, start_sample=194846, stop_sample=196846\n",
      "Processing trial: mrk_code=6, start_sample=198716, stop_sample=200716\n",
      "Processing trial: mrk_code=2, start_sample=202501, stop_sample=204501\n",
      "Processing trial: mrk_code=8, start_sample=206201, stop_sample=208201\n",
      "Processing trial: mrk_code=4, start_sample=209831, stop_sample=211831\n",
      "Processing trial: mrk_code=2, start_sample=213521, stop_sample=215521\n",
      "Processing trial: mrk_code=8, start_sample=217426, stop_sample=219426\n",
      "Processing trial: mrk_code=4, start_sample=221266, stop_sample=223266\n",
      "Processing trial: mrk_code=6, start_sample=224796, stop_sample=226796\n",
      "Processing trial: mrk_code=8, start_sample=228591, stop_sample=230591\n",
      "Processing trial: mrk_code=6, start_sample=232301, stop_sample=234301\n",
      "Processing trial: mrk_code=4, start_sample=236031, stop_sample=238031\n",
      "Processing trial: mrk_code=2, start_sample=239566, stop_sample=241566\n",
      "Processing trial: mrk_code=4, start_sample=243151, stop_sample=245151\n",
      "Processing trial: mrk_code=8, start_sample=246676, stop_sample=248676\n",
      "Processing trial: mrk_code=2, start_sample=250536, stop_sample=252536\n",
      "Processing trial: mrk_code=6, start_sample=254196, stop_sample=256196\n",
      "Processing trial: mrk_code=2, start_sample=257721, stop_sample=259721\n",
      "Processing trial: mrk_code=4, start_sample=261396, stop_sample=263396\n",
      "Processing trial: mrk_code=8, start_sample=265026, stop_sample=267026\n",
      "Processing trial: mrk_code=6, start_sample=268806, stop_sample=270806\n",
      "Processing trial: mrk_code=4, start_sample=272541, stop_sample=274541\n",
      "Processing trial: mrk_code=8, start_sample=276526, stop_sample=278526\n",
      "Processing trial: mrk_code=2, start_sample=280101, stop_sample=282101\n",
      "Processing trial: mrk_code=6, start_sample=284046, stop_sample=286046\n",
      "Processing trial: mrk_code=2, start_sample=287666, stop_sample=289666\n",
      "Processing trial: mrk_code=8, start_sample=291226, stop_sample=293226\n",
      "Processing trial: mrk_code=6, start_sample=295031, stop_sample=297031\n",
      "Processing trial: mrk_code=4, start_sample=298911, stop_sample=300911\n",
      "Processing trial: mrk_code=4, start_sample=310316, stop_sample=312316\n",
      "Processing trial: mrk_code=6, start_sample=314041, stop_sample=316041\n",
      "Processing trial: mrk_code=2, start_sample=317641, stop_sample=319641\n",
      "Processing trial: mrk_code=8, start_sample=321626, stop_sample=323626\n",
      "Processing trial: mrk_code=8, start_sample=325581, stop_sample=327581\n",
      "Processing trial: mrk_code=2, start_sample=329206, stop_sample=331206\n",
      "Processing trial: mrk_code=6, start_sample=333181, stop_sample=335181\n",
      "Processing trial: mrk_code=4, start_sample=336736, stop_sample=338736\n",
      "Processing trial: mrk_code=8, start_sample=340696, stop_sample=342696\n",
      "Processing trial: mrk_code=6, start_sample=344266, stop_sample=346266\n",
      "Processing trial: mrk_code=4, start_sample=348051, stop_sample=350051\n",
      "Processing trial: mrk_code=2, start_sample=351991, stop_sample=353991\n",
      "Processing trial: mrk_code=6, start_sample=355611, stop_sample=357611\n",
      "Processing trial: mrk_code=4, start_sample=359466, stop_sample=361466\n",
      "Processing trial: mrk_code=8, start_sample=363086, stop_sample=365086\n",
      "Processing trial: mrk_code=2, start_sample=366961, stop_sample=368961\n",
      "Processing trial: mrk_code=4, start_sample=370536, stop_sample=372536\n",
      "Processing trial: mrk_code=8, start_sample=374041, stop_sample=376041\n",
      "Processing trial: mrk_code=2, start_sample=377606, stop_sample=379606\n",
      "Processing trial: mrk_code=6, start_sample=381316, stop_sample=383316\n",
      "Processing trial: mrk_code=8, start_sample=384911, stop_sample=386911\n",
      "Processing trial: mrk_code=2, start_sample=388761, stop_sample=390761\n",
      "Processing trial: mrk_code=4, start_sample=392426, stop_sample=394426\n",
      "Processing trial: mrk_code=6, start_sample=396361, stop_sample=398361\n",
      "Processing trial: mrk_code=6, start_sample=399956, stop_sample=401956\n",
      "Processing trial: mrk_code=4, start_sample=403656, stop_sample=405656\n",
      "Processing trial: mrk_code=8, start_sample=407291, stop_sample=409291\n",
      "Processing trial: mrk_code=2, start_sample=410961, stop_sample=412961\n",
      "Processing trial: mrk_code=8, start_sample=414571, stop_sample=416571\n",
      "Processing trial: mrk_code=6, start_sample=418146, stop_sample=420146\n",
      "Processing trial: mrk_code=4, start_sample=421646, stop_sample=423646\n",
      "Processing trial: mrk_code=2, start_sample=425261, stop_sample=427261\n",
      "Processing trial: mrk_code=8, start_sample=428921, stop_sample=430921\n",
      "Processing trial: mrk_code=6, start_sample=432786, stop_sample=434786\n",
      "Processing trial: mrk_code=2, start_sample=436676, stop_sample=438676\n",
      "Processing trial: mrk_code=4, start_sample=440556, stop_sample=442556\n",
      "Processing trial: mrk_code=6, start_sample=444231, stop_sample=446231\n",
      "Processing trial: mrk_code=2, start_sample=447791, stop_sample=449791\n",
      "Processing trial: mrk_code=8, start_sample=451311, stop_sample=453311\n",
      "Processing trial: mrk_code=4, start_sample=455246, stop_sample=457246\n",
      "Processing trial: mrk_code=6, start_sample=458916, stop_sample=460916\n",
      "Processing trial: mrk_code=2, start_sample=462671, stop_sample=464671\n",
      "Processing trial: mrk_code=8, start_sample=466531, stop_sample=468531\n",
      "Processing trial: mrk_code=4, start_sample=470436, stop_sample=472436\n",
      "Processing trial: mrk_code=4, start_sample=474036, stop_sample=476036\n",
      "Processing trial: mrk_code=2, start_sample=477771, stop_sample=479771\n",
      "Processing trial: mrk_code=8, start_sample=481431, stop_sample=483431\n",
      "Processing trial: mrk_code=6, start_sample=485031, stop_sample=487031\n",
      "Processing trial: mrk_code=4, start_sample=488851, stop_sample=490851\n",
      "Processing trial: mrk_code=6, start_sample=492476, stop_sample=494476\n",
      "Processing trial: mrk_code=2, start_sample=496146, stop_sample=498146\n",
      "Processing trial: mrk_code=8, start_sample=500006, stop_sample=502006\n",
      "Processing trial: mrk_code=6, start_sample=503821, stop_sample=505821\n",
      "Processing trial: mrk_code=8, start_sample=507531, stop_sample=509531\n",
      "Processing trial: mrk_code=4, start_sample=511526, stop_sample=513526\n",
      "Processing trial: mrk_code=2, start_sample=515281, stop_sample=517281\n",
      "Processing trial: mrk_code=4, start_sample=519196, stop_sample=521196\n",
      "Processing trial: mrk_code=6, start_sample=522766, stop_sample=524766\n",
      "Processing trial: mrk_code=2, start_sample=526291, stop_sample=528291\n",
      "Processing trial: mrk_code=8, start_sample=529851, stop_sample=531851\n",
      "Processing trial: mrk_code=6, start_sample=533766, stop_sample=535766\n",
      "Processing trial: mrk_code=2, start_sample=537726, stop_sample=539726\n",
      "Processing trial: mrk_code=8, start_sample=541586, stop_sample=543586\n",
      "Processing trial: mrk_code=4, start_sample=545376, stop_sample=547376\n",
      "Processing trial: mrk_code=4, start_sample=549356, stop_sample=551356\n",
      "Processing trial: mrk_code=2, start_sample=553141, stop_sample=555141\n",
      "Processing trial: mrk_code=6, start_sample=556851, stop_sample=558851\n",
      "Processing trial: mrk_code=8, start_sample=560696, stop_sample=562696\n",
      "Processing trial: mrk_code=6, start_sample=564271, stop_sample=566271\n",
      "Processing trial: mrk_code=8, start_sample=568151, stop_sample=570151\n",
      "Processing trial: mrk_code=4, start_sample=571666, stop_sample=573666\n",
      "Processing trial: mrk_code=2, start_sample=575601, stop_sample=577601\n",
      "Processing trial: mrk_code=6, start_sample=579221, stop_sample=581221\n",
      "Processing trial: mrk_code=8, start_sample=582916, stop_sample=584916\n",
      "Processing trial: mrk_code=2, start_sample=586551, stop_sample=588551\n",
      "Processing trial: mrk_code=4, start_sample=590101, stop_sample=592101\n",
      "Processing trial: mrk_code=4, start_sample=593776, stop_sample=595776\n",
      "Processing trial: mrk_code=8, start_sample=597571, stop_sample=599571\n",
      "Processing trial: mrk_code=2, start_sample=601411, stop_sample=603411\n",
      "Processing trial: mrk_code=6, start_sample=605296, stop_sample=607296\n",
      "Processing trial: mrk_code=2, start_sample=616526, stop_sample=618526\n",
      "Processing trial: mrk_code=8, start_sample=620151, stop_sample=622151\n",
      "Processing trial: mrk_code=4, start_sample=624106, stop_sample=626106\n",
      "Processing trial: mrk_code=6, start_sample=627676, stop_sample=629676\n",
      "Processing trial: mrk_code=2, start_sample=631601, stop_sample=633601\n",
      "Processing trial: mrk_code=6, start_sample=635386, stop_sample=637386\n",
      "Processing trial: mrk_code=8, start_sample=638911, stop_sample=640911\n",
      "Processing trial: mrk_code=4, start_sample=642466, stop_sample=644466\n",
      "Processing trial: mrk_code=2, start_sample=646151, stop_sample=648151\n",
      "Processing trial: mrk_code=4, start_sample=650081, stop_sample=652081\n",
      "Processing trial: mrk_code=6, start_sample=653656, stop_sample=655656\n",
      "Processing trial: mrk_code=8, start_sample=657276, stop_sample=659276\n",
      "Processing trial: mrk_code=2, start_sample=660781, stop_sample=662781\n",
      "Processing trial: mrk_code=8, start_sample=664296, stop_sample=666296\n",
      "Processing trial: mrk_code=4, start_sample=667871, stop_sample=669871\n",
      "Processing trial: mrk_code=6, start_sample=671531, stop_sample=673531\n",
      "Processing trial: mrk_code=8, start_sample=675221, stop_sample=677221\n",
      "Processing trial: mrk_code=2, start_sample=679171, stop_sample=681171\n",
      "Processing trial: mrk_code=6, start_sample=682911, stop_sample=684911\n",
      "Processing trial: mrk_code=4, start_sample=686841, stop_sample=688841\n",
      "Processing trial: mrk_code=2, start_sample=690826, stop_sample=692826\n",
      "Processing trial: mrk_code=6, start_sample=694676, stop_sample=696676\n",
      "Processing trial: mrk_code=4, start_sample=698221, stop_sample=700221\n",
      "Processing trial: mrk_code=8, start_sample=701771, stop_sample=703771\n",
      "Processing trial: mrk_code=6, start_sample=705291, stop_sample=707291\n",
      "Processing trial: mrk_code=8, start_sample=708911, stop_sample=710911\n",
      "Processing trial: mrk_code=4, start_sample=712446, stop_sample=714446\n",
      "Processing trial: mrk_code=2, start_sample=716406, stop_sample=718406\n",
      "Processing trial: mrk_code=8, start_sample=720046, stop_sample=722046\n",
      "Processing trial: mrk_code=4, start_sample=723706, stop_sample=725706\n",
      "Processing trial: mrk_code=2, start_sample=727346, stop_sample=729346\n",
      "Processing trial: mrk_code=6, start_sample=731316, stop_sample=733316\n",
      "Processing trial: mrk_code=4, start_sample=735266, stop_sample=737266\n",
      "Processing trial: mrk_code=6, start_sample=739231, stop_sample=741231\n",
      "Processing trial: mrk_code=2, start_sample=742821, stop_sample=744821\n",
      "Processing trial: mrk_code=8, start_sample=746431, stop_sample=748431\n",
      "Processing trial: mrk_code=8, start_sample=750226, stop_sample=752226\n",
      "Processing trial: mrk_code=6, start_sample=754041, stop_sample=756041\n",
      "Processing trial: mrk_code=2, start_sample=758021, stop_sample=760021\n",
      "Processing trial: mrk_code=4, start_sample=761666, stop_sample=763666\n",
      "Processing trial: mrk_code=6, start_sample=765411, stop_sample=767411\n",
      "Processing trial: mrk_code=8, start_sample=768996, stop_sample=770996\n",
      "Processing trial: mrk_code=2, start_sample=772781, stop_sample=774781\n",
      "Processing trial: mrk_code=4, start_sample=776376, stop_sample=778376\n",
      "Processing trial: mrk_code=4, start_sample=780291, stop_sample=782291\n",
      "Processing trial: mrk_code=2, start_sample=783831, stop_sample=785831\n",
      "Processing trial: mrk_code=8, start_sample=787431, stop_sample=789431\n",
      "Processing trial: mrk_code=6, start_sample=790961, stop_sample=792961\n",
      "Processing trial: mrk_code=2, start_sample=794471, stop_sample=796471\n",
      "Processing trial: mrk_code=6, start_sample=798326, stop_sample=800326\n",
      "Processing trial: mrk_code=8, start_sample=802086, stop_sample=804086\n",
      "Processing trial: mrk_code=4, start_sample=805791, stop_sample=807791\n",
      "Processing trial: mrk_code=2, start_sample=809596, stop_sample=811596\n",
      "Processing trial: mrk_code=8, start_sample=813191, stop_sample=815191\n",
      "Processing trial: mrk_code=4, start_sample=816911, stop_sample=818911\n",
      "Processing trial: mrk_code=6, start_sample=820821, stop_sample=822821\n",
      "Processing trial: mrk_code=6, start_sample=824786, stop_sample=826786\n",
      "Processing trial: mrk_code=8, start_sample=828441, stop_sample=830441\n",
      "Processing trial: mrk_code=4, start_sample=832156, stop_sample=834156\n",
      "Processing trial: mrk_code=2, start_sample=835681, stop_sample=837681\n",
      "Processing trial: mrk_code=4, start_sample=839491, stop_sample=841491\n",
      "Processing trial: mrk_code=6, start_sample=843471, stop_sample=845471\n",
      "Processing trial: mrk_code=2, start_sample=847266, stop_sample=849266\n",
      "Processing trial: mrk_code=8, start_sample=851156, stop_sample=853156\n",
      "Processing trial: mrk_code=2, start_sample=854916, stop_sample=856916\n",
      "Processing trial: mrk_code=4, start_sample=858831, stop_sample=860831\n",
      "Processing trial: mrk_code=6, start_sample=862806, stop_sample=864806\n",
      "Processing trial: mrk_code=8, start_sample=866336, stop_sample=868336\n",
      "Processing trial: mrk_code=2, start_sample=869876, stop_sample=871876\n",
      "Processing trial: mrk_code=4, start_sample=873746, stop_sample=875746\n",
      "Processing trial: mrk_code=8, start_sample=877611, stop_sample=879611\n",
      "Processing trial: mrk_code=6, start_sample=881476, stop_sample=883476\n",
      "Processing trial: mrk_code=2, start_sample=885396, stop_sample=887396\n",
      "Processing trial: mrk_code=4, start_sample=889076, stop_sample=891076\n",
      "Processing trial: mrk_code=8, start_sample=892896, stop_sample=894896\n",
      "Processing trial: mrk_code=6, start_sample=896451, stop_sample=898451\n",
      "Processing trial: mrk_code=6, start_sample=900096, stop_sample=902096\n",
      "Processing trial: mrk_code=8, start_sample=903811, stop_sample=905811\n",
      "Processing trial: mrk_code=4, start_sample=907451, stop_sample=909451\n",
      "Processing trial: mrk_code=2, start_sample=911271, stop_sample=913271\n",
      "Processing trial: mrk_code=6, start_sample=922446, stop_sample=924446\n",
      "Processing trial: mrk_code=2, start_sample=926351, stop_sample=928351\n",
      "Processing trial: mrk_code=4, start_sample=930071, stop_sample=932071\n",
      "Processing trial: mrk_code=8, start_sample=934051, stop_sample=936051\n",
      "Processing trial: mrk_code=4, start_sample=937811, stop_sample=939811\n",
      "Processing trial: mrk_code=8, start_sample=941431, stop_sample=943431\n",
      "Processing trial: mrk_code=6, start_sample=944931, stop_sample=946931\n",
      "Processing trial: mrk_code=2, start_sample=948721, stop_sample=950721\n",
      "Processing trial: mrk_code=2, start_sample=952511, stop_sample=954511\n",
      "Processing trial: mrk_code=6, start_sample=956496, stop_sample=958496\n",
      "Processing trial: mrk_code=8, start_sample=960076, stop_sample=962076\n",
      "Processing trial: mrk_code=4, start_sample=963651, stop_sample=965651\n",
      "Processing trial: mrk_code=2, start_sample=967341, stop_sample=969341\n",
      "Processing trial: mrk_code=4, start_sample=971016, stop_sample=973016\n",
      "Processing trial: mrk_code=6, start_sample=974666, stop_sample=976666\n",
      "Processing trial: mrk_code=8, start_sample=978296, stop_sample=980296\n",
      "Processing trial: mrk_code=2, start_sample=982026, stop_sample=984026\n",
      "Processing trial: mrk_code=6, start_sample=985681, stop_sample=987681\n",
      "Processing trial: mrk_code=8, start_sample=989231, stop_sample=991231\n",
      "Processing trial: mrk_code=4, start_sample=992956, stop_sample=994956\n",
      "Processing trial: mrk_code=2, start_sample=996611, stop_sample=998611\n",
      "Processing trial: mrk_code=8, start_sample=1000226, stop_sample=1002226\n",
      "Processing trial: mrk_code=6, start_sample=1004111, stop_sample=1006111\n",
      "Processing trial: mrk_code=4, start_sample=1007631, stop_sample=1009631\n",
      "Processing trial: mrk_code=8, start_sample=1011181, stop_sample=1013181\n",
      "Processing trial: mrk_code=2, start_sample=1015031, stop_sample=1017031\n",
      "Processing trial: mrk_code=4, start_sample=1018726, stop_sample=1020726\n",
      "Processing trial: mrk_code=6, start_sample=1022696, stop_sample=1024696\n",
      "Processing trial: mrk_code=6, start_sample=1026341, stop_sample=1028341\n",
      "Processing trial: mrk_code=8, start_sample=1030176, stop_sample=1032176\n",
      "Processing trial: mrk_code=2, start_sample=1033811, stop_sample=1035811\n",
      "Processing trial: mrk_code=4, start_sample=1037541, stop_sample=1039541\n",
      "Processing trial: mrk_code=2, start_sample=1041106, stop_sample=1043106\n",
      "Processing trial: mrk_code=6, start_sample=1044931, stop_sample=1046931\n",
      "Processing trial: mrk_code=4, start_sample=1048881, stop_sample=1050881\n",
      "Processing trial: mrk_code=8, start_sample=1052666, stop_sample=1054666\n",
      "Processing trial: mrk_code=6, start_sample=1056526, stop_sample=1058526\n",
      "Processing trial: mrk_code=4, start_sample=1060476, stop_sample=1062476\n",
      "Processing trial: mrk_code=2, start_sample=1064351, stop_sample=1066351\n",
      "Processing trial: mrk_code=8, start_sample=1068341, stop_sample=1070341\n",
      "Processing trial: mrk_code=8, start_sample=1071961, stop_sample=1073961\n",
      "Processing trial: mrk_code=4, start_sample=1075796, stop_sample=1077796\n",
      "Processing trial: mrk_code=6, start_sample=1079481, stop_sample=1081481\n",
      "Processing trial: mrk_code=2, start_sample=1083436, stop_sample=1085436\n",
      "Processing trial: mrk_code=2, start_sample=1087201, stop_sample=1089201\n",
      "Processing trial: mrk_code=4, start_sample=1090766, stop_sample=1092766\n",
      "Processing trial: mrk_code=8, start_sample=1094346, stop_sample=1096346\n",
      "Processing trial: mrk_code=6, start_sample=1098176, stop_sample=1100176\n",
      "Processing trial: mrk_code=2, start_sample=1102126, stop_sample=1104126\n",
      "Processing trial: mrk_code=4, start_sample=1105831, stop_sample=1107831\n",
      "Processing trial: mrk_code=8, start_sample=1109761, stop_sample=1111761\n",
      "Processing trial: mrk_code=6, start_sample=1113331, stop_sample=1115331\n",
      "Processing trial: mrk_code=2, start_sample=1116851, stop_sample=1118851\n",
      "Processing trial: mrk_code=4, start_sample=1120791, stop_sample=1122791\n",
      "Processing trial: mrk_code=6, start_sample=1124651, stop_sample=1126651\n",
      "Processing trial: mrk_code=8, start_sample=1128186, stop_sample=1130186\n",
      "Processing trial: mrk_code=4, start_sample=1131986, stop_sample=1133986\n",
      "Processing trial: mrk_code=8, start_sample=1135816, stop_sample=1137816\n",
      "Processing trial: mrk_code=6, start_sample=1139806, stop_sample=1141806\n",
      "Processing trial: mrk_code=2, start_sample=1143546, stop_sample=1145546\n",
      "Processing trial: mrk_code=8, start_sample=1147166, stop_sample=1149166\n",
      "Processing trial: mrk_code=6, start_sample=1150686, stop_sample=1152686\n",
      "Processing trial: mrk_code=2, start_sample=1154631, stop_sample=1156631\n",
      "Processing trial: mrk_code=4, start_sample=1158461, stop_sample=1160461\n",
      "Processing trial: mrk_code=2, start_sample=1162371, stop_sample=1164371\n",
      "Processing trial: mrk_code=4, start_sample=1165921, stop_sample=1167921\n",
      "Processing trial: mrk_code=6, start_sample=1169636, stop_sample=1171636\n",
      "Processing trial: mrk_code=8, start_sample=1173556, stop_sample=1175556\n",
      "Processing trial: mrk_code=6, start_sample=1177396, stop_sample=1179396\n",
      "Processing trial: mrk_code=8, start_sample=1181356, stop_sample=1183356\n",
      "Processing trial: mrk_code=4, start_sample=1185221, stop_sample=1187221\n",
      "Processing trial: mrk_code=2, start_sample=1188811, stop_sample=1190811\n",
      "Processing trial: mrk_code=8, start_sample=1192471, stop_sample=1194471\n",
      "Processing trial: mrk_code=4, start_sample=1196456, stop_sample=1198456\n",
      "Processing trial: mrk_code=6, start_sample=1200196, stop_sample=1202196\n",
      "Processing trial: mrk_code=2, start_sample=1204091, stop_sample=1206091\n",
      "Processing trial: mrk_code=6, start_sample=1208046, stop_sample=1210046\n",
      "Processing trial: mrk_code=8, start_sample=1211991, stop_sample=1213991\n",
      "Processing trial: mrk_code=2, start_sample=1215546, stop_sample=1217546\n",
      "Processing trial: mrk_code=4, start_sample=1219431, stop_sample=1221431\n",
      "cnt_y: [[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "cnt_y: [[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "i_start_stops: [(5001, 7001), (8726, 10726), (12236, 14236), (15941, 17941), (19731, 21731), (23276, 25276), (26901, 28901), (30551, 32551), (34106, 36106), (37921, 39921), (41581, 43581), (45571, 47571), (49536, 51536), (53366, 55366), (57191, 59191), (60946, 62946), (64796, 66796), (68326, 70326), (72191, 74191), (76056, 78056), (79641, 81641), (83536, 85536), (87056, 89056), (90906, 92906), (94461, 96461), (98251, 100251), (102016, 104016), (105871, 107871), (109456, 111456), (113331, 115331), (116831, 118831), (120711, 122711), (124516, 126516), (128061, 130061), (131671, 133671), (135206, 137206), (138826, 140826), (142661, 144661), (146431, 148431), (149971, 151971), (153521, 155521), (157436, 159436), (161036, 163036), (164981, 166981), (168831, 170831), (172761, 174761), (176731, 178731), (180316, 182316), (184166, 186166), (187726, 189726), (191336, 193336), (194846, 196846), (198716, 200716), (202501, 204501), (206201, 208201), (209831, 211831), (213521, 215521), (217426, 219426), (221266, 223266), (224796, 226796), (228591, 230591), (232301, 234301), (236031, 238031), (239566, 241566), (243151, 245151), (246676, 248676), (250536, 252536), (254196, 256196), (257721, 259721), (261396, 263396), (265026, 267026), (268806, 270806), (272541, 274541), (276526, 278526), (280101, 282101), (284046, 286046), (287666, 289666), (291226, 293226), (295031, 297031), (298911, 300911), (310316, 312316), (314041, 316041), (317641, 319641), (321626, 323626), (325581, 327581), (329206, 331206), (333181, 335181), (336736, 338736), (340696, 342696), (344266, 346266), (348051, 350051), (351991, 353991), (355611, 357611), (359466, 361466), (363086, 365086), (366961, 368961), (370536, 372536), (374041, 376041), (377606, 379606), (381316, 383316), (384911, 386911), (388761, 390761), (392426, 394426), (396361, 398361), (399956, 401956), (403656, 405656), (407291, 409291), (410961, 412961), (414571, 416571), (418146, 420146), (421646, 423646), (425261, 427261), (428921, 430921), (432786, 434786), (436676, 438676), (440556, 442556), (444231, 446231), (447791, 449791), (451311, 453311), (455246, 457246), (458916, 460916), (462671, 464671), (466531, 468531), (470436, 472436), (474036, 476036), (477771, 479771), (481431, 483431), (485031, 487031), (488851, 490851), (492476, 494476), (496146, 498146), (500006, 502006), (503821, 505821), (507531, 509531), (511526, 513526), (515281, 517281), (519196, 521196), (522766, 524766), (526291, 528291), (529851, 531851), (533766, 535766), (537726, 539726), (541586, 543586), (545376, 547376), (549356, 551356), (553141, 555141), (556851, 558851), (560696, 562696), (564271, 566271), (568151, 570151), (571666, 573666), (575601, 577601), (579221, 581221), (582916, 584916), (586551, 588551), (590101, 592101), (593776, 595776), (597571, 599571), (601411, 603411), (605296, 607296), (616526, 618526), (620151, 622151), (624106, 626106), (627676, 629676), (631601, 633601), (635386, 637386), (638911, 640911), (642466, 644466), (646151, 648151), (650081, 652081), (653656, 655656), (657276, 659276), (660781, 662781), (664296, 666296), (667871, 669871), (671531, 673531), (675221, 677221), (679171, 681171), (682911, 684911), (686841, 688841), (690826, 692826), (694676, 696676), (698221, 700221), (701771, 703771), (705291, 707291), (708911, 710911), (712446, 714446), (716406, 718406), (720046, 722046), (723706, 725706), (727346, 729346), (731316, 733316), (735266, 737266), (739231, 741231), (742821, 744821), (746431, 748431), (750226, 752226), (754041, 756041), (758021, 760021), (761666, 763666), (765411, 767411), (768996, 770996), (772781, 774781), (776376, 778376), (780291, 782291), (783831, 785831), (787431, 789431), (790961, 792961), (794471, 796471), (798326, 800326), (802086, 804086), (805791, 807791), (809596, 811596), (813191, 815191), (816911, 818911), (820821, 822821), (824786, 826786), (828441, 830441), (832156, 834156), (835681, 837681), (839491, 841491), (843471, 845471), (847266, 849266), (851156, 853156), (854916, 856916), (858831, 860831), (862806, 864806), (866336, 868336), (869876, 871876), (873746, 875746), (877611, 879611), (881476, 883476), (885396, 887396), (889076, 891076), (892896, 894896), (896451, 898451), (900096, 902096), (903811, 905811), (907451, 909451), (911271, 913271), (922446, 924446), (926351, 928351), (930071, 932071), (934051, 936051), (937811, 939811), (941431, 943431), (944931, 946931), (948721, 950721), (952511, 954511), (956496, 958496), (960076, 962076), (963651, 965651), (967341, 969341), (971016, 973016), (974666, 976666), (978296, 980296), (982026, 984026), (985681, 987681), (989231, 991231), (992956, 994956), (996611, 998611), (1000226, 1002226), (1004111, 1006111), (1007631, 1009631), (1011181, 1013181), (1015031, 1017031), (1018726, 1020726), (1022696, 1024696), (1026341, 1028341), (1030176, 1032176), (1033811, 1035811), (1037541, 1039541), (1041106, 1043106), (1044931, 1046931), (1048881, 1050881), (1052666, 1054666), (1056526, 1058526), (1060476, 1062476), (1064351, 1066351), (1068341, 1070341), (1071961, 1073961), (1075796, 1077796), (1079481, 1081481), (1083436, 1085436), (1087201, 1089201), (1090766, 1092766), (1094346, 1096346), (1098176, 1100176), (1102126, 1104126), (1105831, 1107831), (1109761, 1111761), (1113331, 1115331), (1116851, 1118851), (1120791, 1122791), (1124651, 1126651), (1128186, 1130186), (1131986, 1133986), (1135816, 1137816), (1139806, 1141806), (1143546, 1145546), (1147166, 1149166), (1150686, 1152686), (1154631, 1156631), (1158461, 1160461), (1162371, 1164371), (1165921, 1167921), (1169636, 1171636), (1173556, 1175556), (1177396, 1179396), (1181356, 1183356), (1185221, 1187221), (1188811, 1190811), (1192471, 1194471), (1196456, 1198456), (1200196, 1202196), (1204091, 1206091), (1208046, 1210046), (1211991, 1213991), (1215546, 1217546), (1219431, 1221431)]\n",
      "Data shape: (129, 1225545)\n",
      "cnt_y shape: (1225545, 4)\n",
      "i_start_stops: [(5001, 7001), (8726, 10726), (12236, 14236), (15941, 17941), (19731, 21731), (23276, 25276), (26901, 28901), (30551, 32551), (34106, 36106), (37921, 39921), (41581, 43581), (45571, 47571), (49536, 51536), (53366, 55366), (57191, 59191), (60946, 62946), (64796, 66796), (68326, 70326), (72191, 74191), (76056, 78056), (79641, 81641), (83536, 85536), (87056, 89056), (90906, 92906), (94461, 96461), (98251, 100251), (102016, 104016), (105871, 107871), (109456, 111456), (113331, 115331), (116831, 118831), (120711, 122711), (124516, 126516), (128061, 130061), (131671, 133671), (135206, 137206), (138826, 140826), (142661, 144661), (146431, 148431), (149971, 151971), (153521, 155521), (157436, 159436), (161036, 163036), (164981, 166981), (168831, 170831), (172761, 174761), (176731, 178731), (180316, 182316), (184166, 186166), (187726, 189726), (191336, 193336), (194846, 196846), (198716, 200716), (202501, 204501), (206201, 208201), (209831, 211831), (213521, 215521), (217426, 219426), (221266, 223266), (224796, 226796), (228591, 230591), (232301, 234301), (236031, 238031), (239566, 241566), (243151, 245151), (246676, 248676), (250536, 252536), (254196, 256196), (257721, 259721), (261396, 263396), (265026, 267026), (268806, 270806), (272541, 274541), (276526, 278526), (280101, 282101), (284046, 286046), (287666, 289666), (291226, 293226), (295031, 297031), (298911, 300911), (310316, 312316), (314041, 316041), (317641, 319641), (321626, 323626), (325581, 327581), (329206, 331206), (333181, 335181), (336736, 338736), (340696, 342696), (344266, 346266), (348051, 350051), (351991, 353991), (355611, 357611), (359466, 361466), (363086, 365086), (366961, 368961), (370536, 372536), (374041, 376041), (377606, 379606), (381316, 383316), (384911, 386911), (388761, 390761), (392426, 394426), (396361, 398361), (399956, 401956), (403656, 405656), (407291, 409291), (410961, 412961), (414571, 416571), (418146, 420146), (421646, 423646), (425261, 427261), (428921, 430921), (432786, 434786), (436676, 438676), (440556, 442556), (444231, 446231), (447791, 449791), (451311, 453311), (455246, 457246), (458916, 460916), (462671, 464671), (466531, 468531), (470436, 472436), (474036, 476036), (477771, 479771), (481431, 483431), (485031, 487031), (488851, 490851), (492476, 494476), (496146, 498146), (500006, 502006), (503821, 505821), (507531, 509531), (511526, 513526), (515281, 517281), (519196, 521196), (522766, 524766), (526291, 528291), (529851, 531851), (533766, 535766), (537726, 539726), (541586, 543586), (545376, 547376), (549356, 551356), (553141, 555141), (556851, 558851), (560696, 562696), (564271, 566271), (568151, 570151), (571666, 573666), (575601, 577601), (579221, 581221), (582916, 584916), (586551, 588551), (590101, 592101), (593776, 595776), (597571, 599571), (601411, 603411), (605296, 607296), (616526, 618526), (620151, 622151), (624106, 626106), (627676, 629676), (631601, 633601), (635386, 637386), (638911, 640911), (642466, 644466), (646151, 648151), (650081, 652081), (653656, 655656), (657276, 659276), (660781, 662781), (664296, 666296), (667871, 669871), (671531, 673531), (675221, 677221), (679171, 681171), (682911, 684911), (686841, 688841), (690826, 692826), (694676, 696676), (698221, 700221), (701771, 703771), (705291, 707291), (708911, 710911), (712446, 714446), (716406, 718406), (720046, 722046), (723706, 725706), (727346, 729346), (731316, 733316), (735266, 737266), (739231, 741231), (742821, 744821), (746431, 748431), (750226, 752226), (754041, 756041), (758021, 760021), (761666, 763666), (765411, 767411), (768996, 770996), (772781, 774781), (776376, 778376), (780291, 782291), (783831, 785831), (787431, 789431), (790961, 792961), (794471, 796471), (798326, 800326), (802086, 804086), (805791, 807791), (809596, 811596), (813191, 815191), (816911, 818911), (820821, 822821), (824786, 826786), (828441, 830441), (832156, 834156), (835681, 837681), (839491, 841491), (843471, 845471), (847266, 849266), (851156, 853156), (854916, 856916), (858831, 860831), (862806, 864806), (866336, 868336), (869876, 871876), (873746, 875746), (877611, 879611), (881476, 883476), (885396, 887396), (889076, 891076), (892896, 894896), (896451, 898451), (900096, 902096), (903811, 905811), (907451, 909451), (911271, 913271), (922446, 924446), (926351, 928351), (930071, 932071), (934051, 936051), (937811, 939811), (941431, 943431), (944931, 946931), (948721, 950721), (952511, 954511), (956496, 958496), (960076, 962076), (963651, 965651), (967341, 969341), (971016, 973016), (974666, 976666), (978296, 980296), (982026, 984026), (985681, 987681), (989231, 991231), (992956, 994956), (996611, 998611), (1000226, 1002226), (1004111, 1006111), (1007631, 1009631), (1011181, 1013181), (1015031, 1017031), (1018726, 1020726), (1022696, 1024696), (1026341, 1028341), (1030176, 1032176), (1033811, 1035811), (1037541, 1039541), (1041106, 1043106), (1044931, 1046931), (1048881, 1050881), (1052666, 1054666), (1056526, 1058526), (1060476, 1062476), (1064351, 1066351), (1068341, 1070341), (1071961, 1073961), (1075796, 1077796), (1079481, 1081481), (1083436, 1085436), (1087201, 1089201), (1090766, 1092766), (1094346, 1096346), (1098176, 1100176), (1102126, 1104126), (1105831, 1107831), (1109761, 1111761), (1113331, 1115331), (1116851, 1118851), (1120791, 1122791), (1124651, 1126651), (1128186, 1130186), (1131986, 1133986), (1135816, 1137816), (1139806, 1141806), (1143546, 1145546), (1147166, 1149166), (1150686, 1152686), (1154631, 1156631), (1158461, 1160461), (1162371, 1164371), (1165921, 1167921), (1169636, 1171636), (1173556, 1175556), (1177396, 1179396), (1181356, 1183356), (1185221, 1187221), (1188811, 1190811), (1192471, 1194471), (1196456, 1198456), (1200196, 1202196), (1204091, 1206091), (1208046, 1210046), (1211991, 1213991), (1215546, 1217546), (1219431, 1221431)]\n",
      "new_i_start_stops: [(5001, 7001), (8726, 10726), (12236, 14236), (15941, 17941), (19731, 21731), (23276, 25276), (26901, 28901), (30551, 32551), (34106, 36106), (37921, 39921), (41581, 43581), (45571, 47571), (49536, 51536), (53366, 55366), (57191, 59191), (60946, 62946), (64796, 66796), (68326, 70326), (72191, 74191), (76056, 78056), (79641, 81641), (83536, 85536), (87056, 89056), (90906, 92906), (94461, 96461), (98251, 100251), (102016, 104016), (105871, 107871), (109456, 111456), (113331, 115331), (116831, 118831), (120711, 122711), (124516, 126516), (128061, 130061), (131671, 133671), (135206, 137206), (138826, 140826), (142661, 144661), (146431, 148431), (149971, 151971), (153521, 155521), (157436, 159436), (161036, 163036), (164981, 166981), (168831, 170831), (172761, 174761), (176731, 178731), (180316, 182316), (184166, 186166), (187726, 189726), (191336, 193336), (194846, 196846), (198716, 200716), (202501, 204501), (206201, 208201), (209831, 211831), (213521, 215521), (217426, 219426), (221266, 223266), (224796, 226796), (228591, 230591), (232301, 234301), (236031, 238031), (239566, 241566), (243151, 245151), (246676, 248676), (250536, 252536), (254196, 256196), (257721, 259721), (261396, 263396), (265026, 267026), (268806, 270806), (272541, 274541), (276526, 278526), (280101, 282101), (284046, 286046), (287666, 289666), (291226, 293226), (295031, 297031), (298911, 300911), (310316, 312316), (314041, 316041), (317641, 319641), (321626, 323626), (325581, 327581), (329206, 331206), (333181, 335181), (336736, 338736), (340696, 342696), (344266, 346266), (348051, 350051), (351991, 353991), (355611, 357611), (359466, 361466), (363086, 365086), (366961, 368961), (370536, 372536), (374041, 376041), (377606, 379606), (381316, 383316), (384911, 386911), (388761, 390761), (392426, 394426), (396361, 398361), (399956, 401956), (403656, 405656), (407291, 409291), (410961, 412961), (414571, 416571), (418146, 420146), (421646, 423646), (425261, 427261), (428921, 430921), (432786, 434786), (436676, 438676), (440556, 442556), (444231, 446231), (447791, 449791), (451311, 453311), (455246, 457246), (458916, 460916), (462671, 464671), (466531, 468531), (470436, 472436), (474036, 476036), (477771, 479771), (481431, 483431), (485031, 487031), (488851, 490851), (492476, 494476), (496146, 498146), (500006, 502006), (503821, 505821), (507531, 509531), (511526, 513526), (515281, 517281), (519196, 521196), (522766, 524766), (526291, 528291), (529851, 531851), (533766, 535766), (537726, 539726), (541586, 543586), (545376, 547376), (549356, 551356), (553141, 555141), (556851, 558851), (560696, 562696), (564271, 566271), (568151, 570151), (571666, 573666), (575601, 577601), (579221, 581221), (582916, 584916), (586551, 588551), (590101, 592101), (593776, 595776), (597571, 599571), (601411, 603411), (605296, 607296), (616526, 618526), (620151, 622151), (624106, 626106), (627676, 629676), (631601, 633601), (635386, 637386), (638911, 640911), (642466, 644466), (646151, 648151), (650081, 652081), (653656, 655656), (657276, 659276), (660781, 662781), (664296, 666296), (667871, 669871), (671531, 673531), (675221, 677221), (679171, 681171), (682911, 684911), (686841, 688841), (690826, 692826), (694676, 696676), (698221, 700221), (701771, 703771), (705291, 707291), (708911, 710911), (712446, 714446), (716406, 718406), (720046, 722046), (723706, 725706), (727346, 729346), (731316, 733316), (735266, 737266), (739231, 741231), (742821, 744821), (746431, 748431), (750226, 752226), (754041, 756041), (758021, 760021), (761666, 763666), (765411, 767411), (768996, 770996), (772781, 774781), (776376, 778376), (780291, 782291), (783831, 785831), (787431, 789431), (790961, 792961), (794471, 796471), (798326, 800326), (802086, 804086), (805791, 807791), (809596, 811596), (813191, 815191), (816911, 818911), (820821, 822821), (824786, 826786), (828441, 830441), (832156, 834156), (835681, 837681), (839491, 841491), (843471, 845471), (847266, 849266), (851156, 853156), (854916, 856916), (858831, 860831), (862806, 864806), (866336, 868336), (869876, 871876), (873746, 875746), (877611, 879611), (881476, 883476), (885396, 887396), (889076, 891076), (892896, 894896), (896451, 898451), (900096, 902096), (903811, 905811), (907451, 909451), (911271, 913271), (922446, 924446), (926351, 928351), (930071, 932071), (934051, 936051), (937811, 939811), (941431, 943431), (944931, 946931), (948721, 950721), (952511, 954511), (956496, 958496), (960076, 962076), (963651, 965651), (967341, 969341), (971016, 973016), (974666, 976666), (978296, 980296), (982026, 984026), (985681, 987681), (989231, 991231), (992956, 994956), (996611, 998611), (1000226, 1002226), (1004111, 1006111), (1007631, 1009631), (1011181, 1013181), (1015031, 1017031), (1018726, 1020726), (1022696, 1024696), (1026341, 1028341), (1030176, 1032176), (1033811, 1035811), (1037541, 1039541), (1041106, 1043106), (1044931, 1046931), (1048881, 1050881), (1052666, 1054666), (1056526, 1058526), (1060476, 1062476), (1064351, 1066351), (1068341, 1070341), (1071961, 1073961), (1075796, 1077796), (1079481, 1081481), (1083436, 1085436), (1087201, 1089201), (1090766, 1092766), (1094346, 1096346), (1098176, 1100176), (1102126, 1104126), (1105831, 1107831), (1109761, 1111761), (1113331, 1115331), (1116851, 1118851), (1120791, 1122791), (1124651, 1126651), (1128186, 1130186), (1131986, 1133986), (1135816, 1137816), (1139806, 1141806), (1143546, 1145546), (1147166, 1149166), (1150686, 1152686), (1154631, 1156631), (1158461, 1160461), (1162371, 1164371), (1165921, 1167921), (1169636, 1171636), (1173556, 1175556), (1177396, 1179396), (1181356, 1183356), (1185221, 1187221), (1188811, 1190811), (1192471, 1194471), (1196456, 1198456), (1200196, 1202196), (1204091, 1206091), (1208046, 1210046), (1211991, 1213991), (1215546, 1217546), (1219431, 1221431)]\n",
      "X length: 320\n",
      "y length: 320\n",
      "New y after processing: [array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.])]\n",
      "Final y shape: (320,)\n",
      "Tipo di X: <class 'list'>\n",
      "Tipo di y: <class 'numpy.ndarray'>\n",
      "Signal target X shape: (320, 129, 2000)\n",
      "Signal target y shape: (320,)\n",
      "Tipo di signal_target.X: <class 'list'>\n",
      "Signal Target creato. Shape di X: (320, 129, 2000)\n",
      "Shape di y: (320,)\n",
      "Set For Cleaning: <class 'braindecode.datautil.signal_target.SignalAndTarget'>\n",
      "Attributi:  ['X', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'y']\n",
      "(320, 129, 2000)\n",
      "(320, 129, 2000)\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is not causal, uses future data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 events found on stim channel STI 014\n",
      "Event IDs: [2 4 6 8]\n",
      "320 events found on stim channel STI 014\n",
      "Event IDs: [2 4 6 8]\n",
      "Creating RawArray with float64 data, n_channels=45, n_times=612772\n",
      "    Range : 0 ... 612771 =      0.000 ...  1225.542 secs\n",
      "Ready.\n",
      "Dati grezzi CST_raw_mne: (45, 612772)\n",
      "Canali di stimolazione trovati: ['STI 014']\n",
      "2138 events found on stim channel STI 014\n",
      "Event IDs: [    1     2     3     4     5     6    15    16    17    18    19    20\n",
      "    21    22    23    24    25    26    27    28    29    30 65509 65511\n",
      " 65512 65513 65514 65515 65516 65517 65518 65519 65520 65521 65522 65523\n",
      " 65524 65525 65526 65527 65528 65529 65530 65531 65532 65533 65534 65535]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have 325 events shorter than the shortest_event. These are very unusual and you may want to set min_duration to a larger value e.g. x / raw.info['sfreq']. Where x = 1 sample shorter than the shortest event length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(signal_preprocessing)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Evaluate the model based on the weights saved in the '/results' folder\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset_conf, train_conf, results_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Get training and validation data\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSto per chiamare get_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m X_train, _, y_train_onehot, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOSO\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLOSO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misStandard\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43misStandard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDopo get_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape is:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/Desktop/UNIPA CdLM Ing_Informatica/Tesi/CodiceBCI/EEG-ATCNet/preprocess.py:342\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(path, subject, dataset, classes_labels, LOSO, isStandard, isShuffle)\u001b[0m\n\u001b[1;32m    340\u001b[0m     X_test, y_test, _, _, _ \u001b[38;5;241m=\u001b[39m load_CS2R_data_v2(path, subject, \u001b[38;5;28;01mFalse\u001b[39;00m, classes_labels)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHGD\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 342\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_HGD_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     X_test, y_test \u001b[38;5;241m=\u001b[39m load_HGD_data(path, subject\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/UNIPA CdLM Ing_Informatica/Tesi/CodiceBCI/EEG-ATCNet/preprocess_HGD.py:143\u001b[0m, in \u001b[0;36mload_HGD_data\u001b[0;34m(data_path, subject, training, low_cut_hz, debug)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Trial interval, start at -500 already, since improved decoding for networks\u001b[39;00m\n\u001b[1;32m    141\u001b[0m ival \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m4000\u001b[39m]\n\u001b[0;32m--> 143\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_signal_target_from_raw_mne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mival\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m dataset\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mX[clean_trial_mask]\n\u001b[1;32m    145\u001b[0m dataset\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39my[clean_trial_mask]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/braindecode/datautil/trial_segment.py:73\u001b[0m, in \u001b[0;36mcreate_signal_target_from_raw_mne\u001b[0;34m(raw, name_to_start_codes, epoch_ival_ms, name_to_stop_codes, prepad_trials_to_n_samples, one_hot_labels, one_label_per_trial)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl canale \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTI 014\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m non è presente nei dati.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Estrai gli eventi dal canale 'STI 014'\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstim_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTI 014\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmin_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.002\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muint_cast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventi estratti:\u001b[39m\u001b[38;5;124m\"\u001b[39m, events)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Filtra gli eventi con una durata minima\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-139>:10\u001b[0m, in \u001b[0;36mfind_events\u001b[0;34m(raw, stim_channel, output, consecutive, min_duration, shortest_event, mask, uint_cast, mask_type, initial_event, verbose)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mne/event.py:791\u001b[0m, in \u001b[0;36mfind_events\u001b[0;34m(raw, stim_channel, output, consecutive, min_duration, shortest_event, mask, uint_cast, mask_type, initial_event, verbose)\u001b[0m\n\u001b[1;32m    789\u001b[0m     n_short_events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mdiff(events[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m shortest_event)\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_short_events \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 791\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_short_events\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m events shorter than the shortest_event. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThese are very unusual and you may want to set min_duration to a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarger value e.g. x / raw.info[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msfreq\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]. Where x = 1 sample shorter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the shortest event length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m     events_list\u001b[38;5;241m.\u001b[39mappend(events)\n\u001b[1;32m    800\u001b[0m events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(events_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: You have 325 events shorter than the shortest_event. These are very unusual and you may want to set min_duration to a larger value e.g. x / raw.info['sfreq']. Where x = 1 sample shorter than the shortest event length."
     ]
    }
   ],
   "source": [
    "run(\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se min_duration va oltre 0.002 non trova più eventi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmgl52x4BRnm"
   },
   "source": [
    "## DB4 (Soft) Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKWBjWr9BWb5"
   },
   "outputs": [],
   "source": [
    "run(\"db4_soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcAuThEQBWy3"
   },
   "source": [
    "## DB4 (Hard) Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6vR-NHTBaLg"
   },
   "outputs": [],
   "source": [
    "run(\"db4_hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sas6wn-n9bVV"
   },
   "source": [
    "## RDWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AanpQPu49dhp"
   },
   "outputs": [],
   "source": [
    "run(\"rdwt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
